1
00:00:14,660 --> 00:00:17,920
Welcome to the final lesson in
this series of Cucumber School

2
00:00:18,480 --> 00:00:21,700
Over the series we've tried to cover
all the important techniques

3
00:00:21,700 --> 00:00:27,140
and concepts we think you need to become a
successful behaviour-driven developer

4
00:00:28,140 --> 00:00:32,080
We've taught you how to break down
requirements with example mapping

5
00:00:32,080 --> 00:00:35,580
and how to express those examples
as Gherkin scenarios

6
00:00:36,100 --> 00:00:39,960
We've explained the importance of
keeping your features readable

7
00:00:39,960 --> 00:00:44,580
and shown you how to write great, flexible
step definitions to help you achieve that goal

8
00:00:45,820 --> 00:00:50,780
We've also explored the difference between
acceptance tests and unit tests

9
00:00:50,780 --> 00:00:55,460
and demonstrated how the outside in
approach to software development works

10
00:00:55,460 --> 00:00:58,100
using both types of tests
to drive out the solution to your

11
00:00:58,100 --> 00:00:59,640
stakeholders' problems

12
00:01:01,640 --> 00:01:04,820
One glaring omission from
the story so far however

13
00:01:04,820 --> 00:01:08,340
is that our Shouty solution is
nothing more than a domain model

14
00:01:09,320 --> 00:01:12,280
It doesn't have any way for
a user to interact with it

15
00:01:12,960 --> 00:01:15,780
Well, that's all about to change

16
00:01:16,540 --> 00:01:19,800
In this episode, we'll review the code
that's just been written

17
00:01:19,800 --> 00:01:23,720
for the first iteration of
Shouty's web user interface

18
00:01:23,720 --> 00:01:27,420
and show you how to use Selenium WebDriver

19
00:01:27,420 --> 00:01:33,440
a browser automation library to run our
Cucumber scenarios through that user interface

20
00:01:34,460 --> 00:01:38,520
We think it would be irresponsible
to teach you how to use Selenium

21
00:01:38,520 --> 00:01:44,060
without also teaching you about the Agile
testing pyramid and its nemesis

22
00:01:44,060 --> 00:01:45,980
the testing ice cream cone

23
00:01:46,760 --> 00:01:50,120
We've come across too many teams
who have ended up with

24
00:01:50,120 --> 00:01:55,820
miserably slow, unreliable test suites
that cost too much to maintain

25
00:01:55,820 --> 00:01:59,300
because all their Cucumber scenarios
go through the UI

26
00:02:00,060 --> 00:02:03,600
It doesn't have to be this way
and in this episode

27
00:02:03,600 --> 00:02:05,760
we'll show you how to avoid this trap

28
00:02:06,760 --> 00:02:10,560
Let's start by walking you through
the changes that have been happening

29
00:02:10,560 --> 00:02:13,060
in the code base while we've been away

30
00:02:14,400 --> 00:02:17,180
Shouty now has a simple web UI
which displays a form

31
00:02:17,180 --> 00:02:19,780
where a user can shout a message

32
00:02:19,780 --> 00:02:24,020
It won't win any awards for style just yet
but it should be functional at least

33
00:02:25,800 --> 00:02:28,660
We can let Cucumber put the new web app
through its paces

34
00:02:28,660 --> 00:02:33,360
by setting the shouty.testDepth
system property to web

35
00:02:33,360 --> 00:02:34,880
when we run Cucumber

36
00:02:36,380 --> 00:02:41,240
This setting causes the scenarios
to be run through the browser via Selenium

37
00:02:41,240 --> 00:02:42,740
and if you watch closely

38
00:02:42,740 --> 00:02:45,780
you can see the message being typed
into the form as it runs

39
00:02:46,880 --> 00:02:50,680
You can see it's way slower
to run the scenarios via browser

40
00:03:05,820 --> 00:03:10,140
Luckily, we still have our original
much faster version of the acceptance tests

41
00:03:10,140 --> 00:03:12,040
that go directly to the domain model

42
00:03:12,800 --> 00:03:14,460
These run in less than a second

43
00:03:15,100 --> 00:03:19,340
We can run this version by setting
shouty.testDepth to something else

44
00:03:19,340 --> 00:03:21,320
or just leaving it out altogether

45
00:03:25,540 --> 00:03:26,500
Nice!

46
00:03:26,920 --> 00:03:29,660
So we have the best of both worlds it seems

47
00:03:30,440 --> 00:03:33,780
Let's have a look at how this
has been implemented in the features

48
00:03:33,780 --> 00:03:39,740
In the constructor of the Stepdefs class, here
we’re declaring a parameter of type ShoutSupport

49
00:03:39,740 --> 00:03:44,460
This is an abstract class, and we have two
concrete implementations of that class -

50
00:03:44,460 --> 00:03:47,840
DomainShoutSupport and WebShoutSupport

51
00:03:48,860 --> 00:03:53,060
Over here, in CustomPicoFactory
we decide which one to use

52
00:03:53,060 --> 00:03:56,040
based on the shouty.testDepth
system property

53
00:03:57,060 --> 00:04:00,100
We’re telling Cucumber to use this custom
implementation of ObjectFactory

54
00:04:00,100 --> 00:04:02,240
here in cucumber.properties

55
00:04:03,840 --> 00:04:08,460
Both DomainShoutSupport
and WebShoutSupport are polymorphic -

56
00:04:08,460 --> 00:04:12,420
meaning they implement the exact same set of
methods defined in ShoutSupport

57
00:04:13,180 --> 00:04:16,600
As far as the step definitions are concerned
they’re interchangeable

58
00:04:17,180 --> 00:04:22,140
This allows us to use different strategies
for automating the application

59
00:04:24,200 --> 00:04:27,920
DomainShoutSupport contains the familiar
automation code that calls

60
00:04:27,920 --> 00:04:29,420
the domain model directly

61
00:04:31,360 --> 00:04:37,500
WebShoutSupport, on the other hand, is where we
automate Shouty through its new web UI

62
00:04:38,015 --> 00:04:42,111
As you can see, there’s quite a bit
more work being done here

63
00:04:43,640 --> 00:04:48,280
These hooks, startServer and stopServer
start and stop the web server

64
00:04:48,280 --> 00:04:53,120
so that we can be confident there will be no
state leaking from one scenario to the next

65
00:04:54,140 --> 00:05:00,280
This hook, closeAllBrowsers makes sure to close
any open browsers at the end of each scenario

66
00:05:01,840 --> 00:05:06,940
The implementation of seanShout is very different
to the one that hits the domain model directly

67
00:05:07,860 --> 00:05:11,120
First, we 'log in' as Sean -

68
00:05:11,120 --> 00:05:15,400
in fact this just opens the homepage for the app
putting the user’s name in the query string

69
00:05:16,920 --> 00:05:21,780
The browser here is an instance of Selenium’s
FirefoxDriver class

70
00:05:22,480 --> 00:05:27,680
We keep all the browsers used in the scenario
in a Map, with one browser per person

71
00:05:28,760 --> 00:05:33,140
We use the getBrowserFor method to fetch
a browser for Sean

72
00:05:33,140 --> 00:05:35,620
then assign that as the current browser

73
00:05:37,160 --> 00:05:42,360
Next, the shout method asks WebDriver to
find the message box on the form

74
00:05:42,360 --> 00:05:45,860
then types out the contents of the message
into the box

75
00:05:46,360 --> 00:05:50,460
Next, it finds the form’s submit button
and clicks it

76
00:05:54,760 --> 00:05:58,660
Let’s walk through what happens when
a scenario runs using webShoutSupport

77
00:05:59,420 --> 00:06:02,900
When Cucumber runs the
'Sean shouts Free Bagels' step

78
00:06:02,900 --> 00:06:07,620
it searches for the corresponding step definition
and executes the method in the StepDefs class

79
00:06:09,160 --> 00:06:14,780
Now, the code in that step definition calls
the seanShout method on shoutSupport

80
00:06:14,780 --> 00:06:18,520
which is an instance of WebShoutSupport

81
00:06:18,520 --> 00:06:20,780
which in turn creates a WebDriver

82
00:06:20,780 --> 00:06:24,760
and calls the get method on it to
open the homepage as Sean

83
00:06:25,460 --> 00:06:29,680
Selenium WebDriver now tells Firefox to
open a browser at that URL

84
00:06:29,680 --> 00:06:34,240
and when the browser opens that URL
our web server will get a request for the page

85
00:06:34,740 --> 00:06:37,820
We render the page on the server
and the browser displays it

86
00:06:38,840 --> 00:06:43,920
Next, WebShoutSupport asks Selenium to fill out
and submit the shout form

87
00:06:43,920 --> 00:06:46,340
which causes button clicks in the browser

88
00:06:47,300 --> 00:06:51,020
The form is submitted to the server
and the server calls the core domain

89
00:06:51,020 --> 00:06:52,420
to broadcast the shout

90
00:06:53,900 --> 00:07:00,360
In contrast, domainShoutSupport’s implementation
of seanShout calls the domain model directly

91
00:07:01,120 --> 00:07:04,960
Notice this is exactly the same code
as the web server uses

92
00:07:05,660 --> 00:07:08,740
The strategy that talks directly
to the core domain model

93
00:07:08,740 --> 00:07:11,480
gives us fast feedback
and lets us test where the

94
00:07:11,480 --> 00:07:14,220
heart of the application's behaviour
is implemented

95
00:07:14,940 --> 00:07:18,440
We've now added a second strategy
that allows us to prove this behaviour

96
00:07:18,440 --> 00:07:21,080
still works when presented via the web UI

97
00:07:22,111 --> 00:07:24,159
You might be wondering why we need both?

98
00:07:24,680 --> 00:07:28,520
Why didn't we just start driving our way in
from the web UI in the beginning?

99
00:07:30,360 --> 00:07:36,140
We've found that focusing on driving out
a domain model from our scenarios first

100
00:07:36,140 --> 00:07:38,420
modelling by example

101
00:07:38,420 --> 00:07:42,600
gives us fast feedback about
our understanding of new problem domains

102
00:07:43,220 --> 00:07:46,500
We don't get distracted by
solution domain complexities like

103
00:07:46,500 --> 00:07:49,500
web servers, HTML, and so on

104
00:07:49,500 --> 00:07:53,080
while we're still just trying to understand
the core of the problem

105
00:07:54,500 --> 00:07:58,580
In the long run, we also find that
staying focussed on the core domain

106
00:07:58,580 --> 00:08:02,040
helps us build scenarios that are
more stable over time

107
00:08:03,080 --> 00:08:05,980
User interfaces tend to change
a lot more often

108
00:08:05,980 --> 00:08:08,700
than the core business rules of the domain

109
00:08:10,500 --> 00:08:14,500
Building scenarios that make sense
even without a user interface

110
00:08:14,500 --> 00:08:17,680
also helps us to avoid
our tests from becoming too

111
00:08:17,680 --> 00:08:18,940
Imperative

112
00:08:19,960 --> 00:08:23,660
Most teams who write and run their cukes
against the user interface

113
00:08:23,660 --> 00:08:29,180
end it with a lot of incidental detail
in their scenarios about the UI interaction

114
00:08:29,695 --> 00:08:31,231
Solution domain stuff

115
00:08:31,999 --> 00:08:34,559
These scenarios are poor documentation

116
00:08:35,080 --> 00:08:38,820
They're too busy talking about
how the user performs a task

117
00:08:38,820 --> 00:08:41,760
rather than what the user is trying to achieve

118
00:08:42,760 --> 00:08:46,420
For example we might have written
the scenario like this instead

119
00:08:50,260 --> 00:08:53,000
This scenario doesn't illustrate
the behaviour very well

120
00:08:53,760 --> 00:08:57,360
If you didn't know anything about Shouty
and were trying to understand it

121
00:08:57,360 --> 00:09:00,920
through the examples written like this
you'd have a tough time

122
00:09:01,740 --> 00:09:04,040
It makes for lousy documentation

123
00:09:05,540 --> 00:09:11,440
Notice how the language used in this scenario
the URLs, the CSS selectors

124
00:09:11,440 --> 00:09:14,360
even the filling in fields
and clicking of buttons

125
00:09:14,360 --> 00:09:17,560
is from the solution domain
not the problem domain

126
00:09:18,335 --> 00:09:22,175
It tells you nothing about
your team's ubiquitous language

127
00:09:23,960 --> 00:09:26,900
Finally, this scenario is brittle

128
00:09:26,900 --> 00:09:31,200
If you need to change the details
of the interaction for sending a shout

129
00:09:31,200 --> 00:09:33,340
such as the way you authenticate

130
00:09:33,340 --> 00:09:36,760
you'd need to come back
and change every scenario that involves shouting

131
00:09:37,535 --> 00:09:43,935
By pushing the how down
your scenarios will remain truer for longer

132
00:09:44,700 --> 00:09:48,060
The opposite of the imperative style
where we express the scenarios

133
00:09:48,060 --> 00:09:51,160
using problem domain language is known as a

134
00:09:51,160 --> 00:09:52,640
Declarative Style

135
00:09:53,340 --> 00:09:57,540
In this style, we try to describe
what the user is trying to achieve

136
00:09:57,540 --> 00:09:59,520
rather than how they do it

137
00:10:00,840 --> 00:10:04,640
Thanks to the declarative style
we've been using through the rest of the series

138
00:10:04,640 --> 00:10:07,980
we were able to easily swap in a
different strategy for automating

139
00:10:07,980 --> 00:10:12,100
our application through the web
without changing our specifications

140
00:10:13,120 --> 00:10:18,900
If there are other interfaces to our application
like a rest API or a mobile app

141
00:10:18,900 --> 00:10:22,300
we can continue to use this pattern
adding new strategies

142
00:10:22,300 --> 00:10:25,660
that run our scenarios through
these new layers of the stack

143
00:10:26,940 --> 00:10:33,400
Remember, each of these strategies uses
exactly the same scenarios and step definitions

144
00:10:34,520 --> 00:10:40,120
This means the investment you put into
writing your scenarios pays back over and over

145
00:10:40,120 --> 00:10:43,160
as you reuse them to validate
the behaviour of the application

146
00:10:43,160 --> 00:10:44,820
from these different perspectives

147
00:10:45,640 --> 00:10:49,880
This is a major advantage of having
pushed the details of how Sean shouts

148
00:10:49,880 --> 00:10:51,260
down into a helper method

149
00:10:52,040 --> 00:10:54,780
If this detail was still up
in the step definition

150
00:10:54,780 --> 00:10:59,720
or worse, in the scenario itself
we wouldn't have this flexibility

151
00:11:02,020 --> 00:11:05,560
In general, the structure emerging
in our application and test code

152
00:11:05,560 --> 00:11:09,200
is called a ports and adapters architecture, or

153
00:11:09,200 --> 00:11:10,900
Hexagonal Architecture

154
00:11:11,740 --> 00:11:14,640
You can think of ports and adapters
as a direct analogy

155
00:11:14,640 --> 00:11:17,380
to physical devices with plugs and sockets

156
00:11:18,140 --> 00:11:21,320
For example, the HDMI port on this laptop

157
00:11:21,320 --> 00:11:24,900
lets me plug in any kind of display
that also has a HDMI port

158
00:11:25,840 --> 00:11:30,420
If I need to use a VGA display
I can use an adapter between the two

159
00:11:31,720 --> 00:11:34,140
In a hexagonal architecture

160
00:11:34,140 --> 00:11:37,340
the inner hexagon contains
your core business logic

161
00:11:38,340 --> 00:11:42,360
This is where the if statements that
deliver the most value to your stakeholders

162
00:11:42,360 --> 00:11:43,240
should live

163
00:11:44,460 --> 00:11:47,160
The inner hexagon knows nothing about
the outside world:

164
00:11:47,160 --> 00:11:52,700
your web servers, your databases, your email
sending service, or your enterprise message bus

165
00:11:53,400 --> 00:11:55,660
It's pure business logic

166
00:11:56,740 --> 00:12:00,860
We expose this core behaviour via
one or more ports

167
00:12:01,660 --> 00:12:05,760
A port is really just a protocol
an API if you like

168
00:12:06,280 --> 00:12:10,760
Any component who understands that protocol
can then plug in and interact

169
00:12:10,760 --> 00:12:12,600
with the core through the port

170
00:12:13,700 --> 00:12:15,900
We call that component an adapter

171
00:12:16,440 --> 00:12:21,120
It's the adapter's job to expose
the core domain logic to the outside world

172
00:12:23,680 --> 00:12:26,580
In Shouty, there's just one port

173
00:12:26,580 --> 00:12:30,860
the API to our domain model
made up of the Person and Network classes

174
00:12:31,840 --> 00:12:35,200
We've plugged in two different adapters
to this little port:

175
00:12:35,200 --> 00:12:38,840
the WebApp, which exposes
Shouty's core domain over the web

176
00:12:38,840 --> 00:12:42,220
for users (or Selenium WebDriver)
to interact with

177
00:12:43,140 --> 00:12:45,360
And DomainShoutSupport

178
00:12:45,360 --> 00:12:48,000
which lets Cucumber
drive the application directly

179
00:12:48,767 --> 00:12:51,839
Both are clients of the same API

180
00:12:54,140 --> 00:12:59,000
The hexagonal architecture is a terrific fit
for teams who care about testability

181
00:12:59,560 --> 00:13:03,020
In fact, it was invented precisely
to allow for testability

182
00:13:03,020 --> 00:13:07,200
back in the days when thick client GUIs
were impossible to automate

183
00:13:07,900 --> 00:13:11,040
By separating the core domain logic from the GUI

184
00:13:11,040 --> 00:13:16,500
these TDD pioneers were able to plug
their tests into the same port as the GUI

185
00:13:16,500 --> 00:13:19,500
and still test most of
the application's behaviour

186
00:13:20,760 --> 00:13:24,320
If you have the discipline
to keep your code separated like this

187
00:13:24,320 --> 00:13:26,160
you benefit from being able to
run the tests

188
00:13:26,160 --> 00:13:30,120
against the most business-valuable
lines of code in your codebase

189
00:13:30,120 --> 00:13:33,820
the core domain
in the shortest amount of time

190
00:13:35,100 --> 00:13:38,920
Tests that hit pure business logic
can run lightning fast

191
00:13:38,920 --> 00:13:41,860
meaning it's cheap to get
really thorough feedback

192
00:13:41,860 --> 00:13:44,580
about whether that logic is behaving correctly

193
00:13:45,860 --> 00:13:47,400
Let's get back to the code

194
00:13:48,100 --> 00:13:52,620
To give us a way to test the app manually
the Shouty developers have kindly added this

195
00:13:52,620 --> 00:13:54,720
ManualTestServer class

196
00:13:54,720 --> 00:13:58,400
which starts the web server pre-configured
with some familiar test data

197
00:13:59,420 --> 00:14:01,500
This means we're able to
test the web app

198
00:14:01,500 --> 00:14:05,560
without having to create accounts for people -
a feature we don't have yet!

199
00:14:06,960 --> 00:14:10,660
So we should be able to
open our browser tab as Sean

200
00:14:10,660 --> 00:14:15,100
then another tab as Lucy
send a shout from Sean

201
00:14:15,100 --> 00:14:21,180
refresh Lucy's page and see- 
wait a minute! Where's Sean Shout?

202
00:14:22,460 --> 00:14:23,900
This is odd -

203
00:14:23,900 --> 00:14:28,860
The scenario is passing
but there's nothing appearing on Lucy's page

204
00:14:29,887 --> 00:14:31,167
What's going on?

205
00:14:32,959 --> 00:14:37,311
The answer lies in the implementation
of our Then step

206
00:14:38,600 --> 00:14:41,340
Reading it, we can see that
the step definition

207
00:14:41,340 --> 00:14:44,700
is going directly to the domain model
to discover the messages

208
00:14:44,700 --> 00:14:46,020
that Lucy has heard

209
00:14:47,200 --> 00:14:51,660
This shouldn't have been a surprise to us -
it's always been that way -

210
00:14:51,660 --> 00:14:57,100
but since our When step now hits the UI
we would expect this Then step

211
00:14:57,100 --> 00:14:59,320
to also adopt the same strategy

212
00:15:00,940 --> 00:15:05,040
When you start to mix different
depths of testing as we’re doing here

213
00:15:05,040 --> 00:15:10,600
a good rule of thumb is to keep the depth of your
When and Then steps consistent

214
00:15:11,780 --> 00:15:15,800
It’s often advisable to bypass layers
and reach down deeper into the stack

215
00:15:15,800 --> 00:15:18,780
to set up state in the Given steps

216
00:15:19,580 --> 00:15:22,740
But if we carry out an action via the UI

217
00:15:22,740 --> 00:15:27,220
the outcome check in the Then step
should also be done through the UI

218
00:15:29,540 --> 00:15:34,100
Let’s remedy this situation by
pushing the code in this step definition

219
00:15:34,100 --> 00:15:35,420
into a helper method

220
00:15:36,460 --> 00:15:38,060
Then we’ll be able to have
two different strategies

221
00:15:38,060 --> 00:15:40,540
for checking the messages
that a user has heard

222
00:15:41,840 --> 00:15:44,840
Once we have a failing test for
the web strategy

223
00:15:44,840 --> 00:15:49,240
we can drive out the behaviour in the UI
to display the user’s messages

224
00:15:50,280 --> 00:15:53,100
We’ll focus on a single scenario
while we do this work

225
00:15:54,020 --> 00:15:57,440
Once we’ve got that one passing
to our satisfaction

226
00:15:57,440 --> 00:16:00,520
we can apply the same change across
the rest of the scenarios

227
00:16:01,800 --> 00:16:06,920
This very basic scenario, where Lucy hears Sean
is a good place to start

228
00:16:10,380 --> 00:16:15,700
Let's extract a method, getMessagesHeardBy
from the body of the step definition

229
00:16:15,700 --> 00:16:18,440
and put it in our DomainShoutSupport

230
00:16:30,220 --> 00:16:32,080
That scenario is still passing

231
00:16:32,620 --> 00:16:33,140
Good

232
00:16:34,360 --> 00:16:36,360
Now, when we run it through the web

233
00:16:36,360 --> 00:16:39,040
we’re shown we need to add
that method to WebShoutSupport

234
00:16:40,520 --> 00:16:42,560
How will we fetch the messages heard?

235
00:16:45,820 --> 00:16:47,680
The first thing we’ll need to do is log in

236
00:16:47,680 --> 00:16:50,180
to make sure we’re reading the messages
for the correct user

237
00:16:50,687 --> 00:16:53,247
So we can reuse this
helper method we’ve already built

238
00:16:54,527 --> 00:16:58,111
Now, we’ll need to
scrape the messages off the HTML page

239
00:16:59,135 --> 00:17:02,719
Remember we’re going test-first here
so we don’t have this markup yet

240
00:17:03,480 --> 00:17:04,800
That's not a problem

241
00:17:04,800 --> 00:17:08,600
We can use the test to help us design
what the markup should look like

242
00:17:10,140 --> 00:17:15,000
Let’s assume that each message will be
an element with a message class on it

243
00:17:16,100 --> 00:17:19,680
We can ask Selenium to give us all
the elements with that class

244
00:17:20,640 --> 00:17:24,220
That gives us a list of
Selenium WebDriver Elements

245
00:17:24,220 --> 00:17:27,560
which we can then transform into
a list of their text content

246
00:17:35,120 --> 00:17:36,660
Let's watch this test fail

247
00:17:40,640 --> 00:17:41,660
That looks OK.

248
00:17:42,600 --> 00:17:44,640
Let's play fake it till you make it

249
00:17:44,640 --> 00:17:47,260
just to check this assertion
is doing the right thing

250
00:17:47,780 --> 00:17:51,620
We’ll hard-code the HTML we want
into the template, here

251
00:17:53,300 --> 00:17:56,220
This gives us a chance to
talk with our designer about the markup

252
00:17:57,260 --> 00:18:01,860
We go over for a chat and he loves it
so we can press on!

253
00:18:08,340 --> 00:18:12,200
The next step is to
make the HTML template dynamic

254
00:18:12,200 --> 00:18:15,940
and have it display the actual list of
messages heard by the user

255
00:18:16,700 --> 00:18:20,540
We could continue using the
Cucumber scenario to drive this out

256
00:18:20,540 --> 00:18:25,160
but it would be better to zoom in and focus
on some unit tests for the web app now

257
00:18:26,180 --> 00:18:29,740
That way, if this behaviour ever
slips loose in the future

258
00:18:29,740 --> 00:18:33,600
there will be a unit test pointing us
to exactly where we need to go to fix it

259
00:18:34,879 --> 00:18:38,975
Luckily, the web app has already been built
with some unit tests around it

260
00:18:40,260 --> 00:18:47,520
These tests load the HttpServlet in isolation
passing in a map of people

261
00:18:47,520 --> 00:18:49,720
that just contains test doubles

262
00:18:50,400 --> 00:18:53,720
We could have used real instances
from our core domain model

263
00:18:53,720 --> 00:18:57,780
but as we explained in the last episode
using test doubles helps us to see

264
00:18:57,780 --> 00:19:02,360
the protocol on the port between the web app
adapter and our core domain

265
00:19:03,660 --> 00:19:08,140
We’ve abstracted some of the nitty-gritty
of calling the Servlet into a base class

266
00:19:08,140 --> 00:19:09,960
which you can examine for yourself

267
00:19:15,583 --> 00:19:19,727
We need a new test for the GET request
which simulates the situation where

268
00:19:19,727 --> 00:19:22,520
Lucy has heard a couple of messages

269
00:19:23,000 --> 00:19:24,520
and views her homepage

270
00:19:44,000 --> 00:19:48,100
We’d expect to be able to find the message text
in each of the message elements

271
00:19:54,751 --> 00:19:59,871
When we run this, it fails because
we’re just hard-coding the message at the moment

272
00:20:00,380 --> 00:20:02,180
Let’s TDD our solution

273
00:20:04,440 --> 00:20:07,580
If you’d like to try this yourself
just pause the video here and

274
00:20:07,580 --> 00:20:10,660
see if you can figure out what to do next
before we show you

275
00:20:12,920 --> 00:20:18,900
Starting in the template, we can look for
a local variable, let’s call it messagesHeard

276
00:20:18,900 --> 00:20:20,740
and iterate over it

277
00:20:20,740 --> 00:20:23,420
For each message, we’ll write a message element

278
00:20:24,920 --> 00:20:25,580
There

279
00:20:26,500 --> 00:20:30,160
Now we need to set that messagesHeard
variable for the template

280
00:20:30,160 --> 00:20:34,680
We do that from within the doGet request handler
method in the web servlet

281
00:20:35,967 --> 00:20:39,551
We need to put the messagesHeard into this context map

282
00:20:40,320 --> 00:20:45,340
Helpfully we have this getUser method that
fetches the right user from the people map

283
00:20:45,340 --> 00:20:48,620
based on the query string parameter used in the request

284
00:20:48,620 --> 00:20:50,040
Let’s give that a try

285
00:20:51,583 --> 00:20:55,679
Great! Suddenly everything is green

286
00:20:56,960 --> 00:21:02,180
Try a quick manual test for yourself
creating a couple of tabs as Sean and Lucy

287
00:21:02,180 --> 00:21:04,900
and satisfy yourself that it’s working now

288
00:21:05,880 --> 00:21:08,280
Now that we’ve proved our
getMessagesHeardBy method

289
00:21:08,280 --> 00:21:11,120
works for both domain and web strategies

290
00:21:11,120 --> 00:21:14,140
let’s use that method in
all the step definitions

291
00:21:14,140 --> 00:21:17,280
so that every scenario
that checks for messagesHeard

292
00:21:17,280 --> 00:21:19,820
will do that check in a consistent way

293
00:21:20,920 --> 00:21:26,040
This is just a matter of finding each call
to ask a Person domain object for messagesHeard

294
00:21:26,040 --> 00:21:28,700
and converting it to use
our new helper method instead

295
00:21:32,160 --> 00:21:34,720
Let's run all the scenarios in the shout feature

296
00:21:48,920 --> 00:21:51,740
Great. It looks like we're done

297
00:21:52,520 --> 00:21:56,020
If we look at the other feature
Premium accounts

298
00:21:56,020 --> 00:21:59,580
we can see that there’s
a similar problem to the one we’ve just resolved

299
00:22:00,320 --> 00:22:05,300
This last step
'Then Sean should have n credits'

300
00:22:05,300 --> 00:22:08,520
goes direct to the domain model
to check Sean’s credits

301
00:22:08,520 --> 00:22:11,260
rather than having that
extra layer of indirection

302
00:22:11,260 --> 00:22:14,780
that would allow us to use a domain
or a web strategy for the check

303
00:22:15,800 --> 00:22:19,120
It will be useful practice for you
to go through and apply

304
00:22:19,120 --> 00:22:22,100
exactly what we just did to this step definition

305
00:22:23,100 --> 00:22:25,400
We'll leave that as an exercise for you

306
00:22:27,460 --> 00:22:29,760
Let's fast-forward to the point
where this is done

307
00:22:31,160 --> 00:22:35,040
Now, we can run all of our scenarios
at both levels

308
00:22:35,040 --> 00:22:38,340
against the domain, and against the web UI

309
00:22:39,620 --> 00:22:41,160
This is awesome!

310
00:22:42,540 --> 00:22:43,840
Isn't it?

311
00:22:43,840 --> 00:22:48,080
We've talked a lot about the benefits of
automated tests in this series

312
00:22:48,080 --> 00:22:51,900
but let’s consider the flip side for a moment
and look at the costs

313
00:22:53,440 --> 00:22:57,280
Every automated test in your system
comes at a cost

314
00:22:58,040 --> 00:23:01,060
You have the cost of 
writing it in the first place

315
00:23:01,060 --> 00:23:04,420
the cost of waiting for it to run each time

316
00:23:04,420 --> 00:23:09,200
the cost of changing it when the
desired behaviour of the application changes

317
00:23:09,200 --> 00:23:13,420
and the cost of debugging it
when it fails for no good reason

318
00:23:15,020 --> 00:23:18,840
When the majority of your tests hit
the application through the user interface

319
00:23:18,840 --> 00:23:20,840
you get a great benefit

320
00:23:20,840 --> 00:23:24,920
from knowing that each scenario
is using the system exactly as a user would

321
00:23:25,980 --> 00:23:29,900
Yet the downside is that
these tests are much slower to run

322
00:23:29,900 --> 00:23:31,840
and are often also much less reliable

323
00:23:33,376 --> 00:23:37,008
A well-known metaphor to help you
think about this problem is the

324
00:23:37,008 --> 00:23:39,008
Agile Testing Pyramid

325
00:23:40,040 --> 00:23:44,760
At the base of the pyramid
you have a large number of unit tests

326
00:23:44,760 --> 00:23:51,180
shallow tests that directly hit isolated
individual classes and modules in your solution

327
00:23:52,840 --> 00:23:59,300
The pyramid gets narrower as you go up
indicating that as the depth of tests increases

328
00:23:59,300 --> 00:24:01,040
the less of them you should have

329
00:24:01,740 --> 00:24:05,160
At the very top of the pyramid
where the tests go right through

330
00:24:05,160 --> 00:24:07,740
the whole application stack

331
00:24:07,740 --> 00:24:09,480
you want as few as possible

332
00:24:10,440 --> 00:24:13,820
Just enough to give you confidence
the thing is working

333
00:24:15,620 --> 00:24:18,720
When you drive most of
your behaviour through the GUI

334
00:24:18,720 --> 00:24:23,280
you end up with the opposite -
more of a testing ice cream cone

335
00:24:24,060 --> 00:24:29,620
Now I love an ice cream on a hot summer’s day
but when your test suite looks like this

336
00:24:29,620 --> 00:24:33,640
you’re waiting hours for test results
and there are generally at least

337
00:24:33,640 --> 00:24:37,120
one or two random failures in every build

338
00:24:40,960 --> 00:24:44,560
Although we have the choice to
run every Shouty scenario through the GUI

339
00:24:44,560 --> 00:24:48,720
the Agile Testing Pyramid tells us
that would be a bad idea

340
00:24:49,840 --> 00:24:56,100
We need to select a few representative or
key examples to run through the web UI

341
00:24:56,100 --> 00:24:58,360
and run the rest through the domain

342
00:24:59,392 --> 00:25:01,440
How do we choose those key examples?

343
00:25:02,976 --> 00:25:05,792
Let’s try and think about
what could possibly go wrong

344
00:25:06,560 --> 00:25:10,040
We want to identify the minimum number of
scenarios that would give us confidence

345
00:25:10,040 --> 00:25:11,420
the system is working

346
00:25:12,120 --> 00:25:15,280
Remember: both our core domain
and our web server

347
00:25:15,280 --> 00:25:17,660
are protected by their own unit tests

348
00:25:17,660 --> 00:25:20,380
so we just need a few checks
for basic correctness

349
00:25:21,000 --> 00:25:26,280
Would it be enough to just test this scenario
the one where the listener is within range?

350
00:25:27,296 --> 00:25:30,112
If we did that, what could possibly go wrong?

351
00:25:31,640 --> 00:25:34,340
With our tester’s hat on
we can imagine a bug

352
00:25:34,340 --> 00:25:37,800
where the web server’s template
didn’t render multiple messages

353
00:25:38,660 --> 00:25:40,700
This scenario only works for one

354
00:25:41,640 --> 00:25:45,480
So we could add this scenario
the one where there are two shouts

355
00:25:46,240 --> 00:25:49,128
Yet we’d easily catch that bug in manual testing

356
00:25:49,128 --> 00:25:52,128
and could then pin it down with
a unit test on the web server

357
00:25:53,408 --> 00:25:56,736
So we don’t need to run this as a
full-stack test every time

358
00:25:57,500 --> 00:25:58,840
In fact

359
00:25:58,840 --> 00:26:01,340
to do so would be wasteful

360
00:26:03,140 --> 00:26:06,720
How about the scenario about
the listener being out of range?

361
00:26:07,540 --> 00:26:10,980
If we skip that in our web-depth Cucumber run

362
00:26:10,980 --> 00:26:13,900
would we leave ourselves vulnerable
to a dangerous bug?

363
00:26:15,420 --> 00:26:19,240
Well, it’s true that if people heard messages
that were not meant for them

364
00:26:19,240 --> 00:26:21,560
it could make us look pretty bad

365
00:26:22,592 --> 00:26:24,640
But how likely is this to happen?

366
00:26:25,400 --> 00:26:28,120
That logic is all in the core domain

367
00:26:28,120 --> 00:26:31,540
the web server just renders
the messages returned by the core

368
00:26:32,320 --> 00:26:35,904
So there’s almost a zero risk of
this bug ever leaking out

369
00:26:36,672 --> 00:26:40,256
Again, a full-stack test for this
behaviour would be wasteful

370
00:26:42,820 --> 00:26:45,820
Although the same goes for
the logic about a long message

371
00:26:45,820 --> 00:26:49,300
we know that there’s potential for
there to be bugs in the interaction

372
00:26:49,300 --> 00:26:51,880
of the UI for longer messages

373
00:26:51,880 --> 00:26:53,820
so it makes sense for us to run this one

374
00:26:54,600 --> 00:26:57,500
Let’s mark it up as @high-risk

375
00:26:57,500 --> 00:27:01,400
and mark the one where the listener is
within range as @high-impact

376
00:27:02,280 --> 00:27:04,080
We’ll explain these terms in a moment

377
00:27:05,440 --> 00:27:12,260
Now, we can run the tests at the top of our pyramid
using those tags and the web testDepth setting

378
00:27:13,280 --> 00:27:17,800
Now we have three different levels of tests in
our pyramid that we want to run to check our code

379
00:27:18,440 --> 00:27:19,940
The unit tests

380
00:27:19,940 --> 00:27:25,300
the core domain acceptance tests
and the key examples running as full-stack tests

381
00:27:27,360 --> 00:27:31,960
Let's set up our maven configuration to run
all of these tests first with a single command

382
00:27:33,520 --> 00:27:37,260
Maven already runs our unit and domain-level
acceptance tests automatically

383
00:27:37,260 --> 00:27:38,880
using the surefire plugin

384
00:27:39,600 --> 00:27:44,440
We can add extra configuration to our pom.xml
to tell surefire to run a second execution

385
00:27:44,440 --> 00:27:47,080
of the tests with different configuration

386
00:27:48,352 --> 00:27:50,912
Just add a surefire plugin node like this

387
00:27:51,680 --> 00:27:56,032
then an execution node with an id of
web-acceptance-tests

388
00:27:57,312 --> 00:28:01,408
Now we attach it to the test goal -
the one maven runs by default

389
00:28:02,440 --> 00:28:05,960
We configure the execution by excluding
all the unit tests -

390
00:28:05,960 --> 00:28:07,840
no need to run those again

391
00:28:07,840 --> 00:28:11,420
and setting the argline to use
the testDepth of web

392
00:28:11,420 --> 00:28:14,256
with the Cucumber options set to run
only those scenarios tagged

393
00:28:14,260 --> 00:28:16,260
as either high impact or high risk

394
00:28:17,720 --> 00:28:18,300
There

395
00:28:18,900 --> 00:28:21,960
Now when we run `mvn test`
from the command-line

396
00:28:21,960 --> 00:28:26,400
it runs all three layers of our testing pyramid
starting from the bottom up

397
00:28:31,100 --> 00:28:32,380
One last thing:

398
00:28:32,900 --> 00:28:37,800
When we automate web pages, we need to
refer to user interface elements and actions

399
00:28:37,800 --> 00:28:40,320
buttons, links, text, clicks, etc

400
00:28:41,080 --> 00:28:45,540
This is solution domain jargon
we’ve managed to keep out of our scenarios

401
00:28:45,540 --> 00:28:46,540
and that’s good!

402
00:28:47,240 --> 00:28:48,880
But it has to go somewhere

403
00:28:50,300 --> 00:28:53,520
On larger projects, it becomes useful
to create abstractions called

404
00:28:53,520 --> 00:28:56,520
page objects to represent
the things being filled in

405
00:28:56,520 --> 00:28:58,240
clicked, and examined for content

406
00:28:58,960 --> 00:29:03,600
For example, we might have a homepage object
with a method called shout

407
00:29:03,600 --> 00:29:07,460
that encapsulated the calls to interact
with the elements on the web page

408
00:29:07,968 --> 00:29:12,576
This allows you to easily reuse code
and keep it easy to read

409
00:29:13,080 --> 00:29:15,920
You can easily build page objects on your own

410
00:29:15,920 --> 00:29:20,180
but if you’re feeling lazy
Selenium ships with a PageFactory class

411
00:29:20,180 --> 00:29:23,080
that reduces the amount of boilerplate code
you need to write

412
00:29:24,600 --> 00:29:30,460
The page objects pattern is a great fit
for keeping your web automation code tidy

413
00:29:30,460 --> 00:29:33,720
but we strongly recommend that you try to

414
00:29:33,720 --> 00:29:37,560
push as many of your tests
down the pyramid first

415
00:29:38,660 --> 00:29:42,080
You can use page objects together with
a hexagonal architecture pattern

416
00:29:42,080 --> 00:29:44,000
we’ve shown you in this episode

417
00:29:44,000 --> 00:29:46,800
so that when you do need to hit the web UI

418
00:29:46,800 --> 00:29:49,440
you can do that through neat and tidy code

419
00:29:50,200 --> 00:29:53,200
That's it kids, school's out!

420
00:29:53,200 --> 00:29:55,840
Time to step out into the real world

421
00:29:57,120 --> 00:30:02,760
This has been an intense episode
and we’ve thrown a lot of new concepts at you -

422
00:30:02,760 --> 00:30:08,140
the hexagonal architecture, the strategy
pattern and the agile testing pyramid

423
00:30:09,400 --> 00:30:15,280
Please take time to watch this video over
a few times until you understand these concepts

424
00:30:15,280 --> 00:30:18,120
and study the exercises and reflection questions

425
00:30:19,320 --> 00:30:25,020
We want you to remember that acceptance tests
don’t have to be full-stack tests

426
00:30:25,800 --> 00:30:28,620
In fact, it’s often a mistake if they are

427
00:30:29,960 --> 00:30:35,520
Don’t fall into the trap of building yet another
testing ice cream cone for your project

428
00:30:36,040 --> 00:30:39,140
Have developers and testers work side-by-side

429
00:30:39,140 --> 00:30:43,360
to maximise the value you get
from your testing investment

430
00:30:43,360 --> 00:30:47,560
by pushing as many tests
as you can down to the lowest level

431
00:30:48,580 --> 00:30:54,760
The responsibility for the health and wellbeing
of the world’s Cucumber suites rests with you now

432
00:30:55,740 --> 00:30:58,300
Use your knowledge wisely!

433
00:31:00,864 --> 00:31:05,472
If you remember one thing from
the video series, remember this:

434
00:31:06,496 --> 00:31:09,824
The software you write is just a model -

435
00:31:10,840 --> 00:31:14,680
a model of your team's understanding
of the problem domain

436
00:31:15,940 --> 00:31:20,320
The better that understanding is
the better the software will be

437
00:31:21,600 --> 00:31:26,200
Put your effort into understanding
the problem together

438
00:31:26,200 --> 00:31:29,520
and the software will take care of itself

439
00:31:31,840 --> 00:31:34,580
Goodbye from all of us on Cucumber School

440
00:31:34,580 --> 00:31:36,200
and have fun out there!

441
00:31:38,740 --> 00:31:40,700
Captions created by Jayson Smith for Cucumber Ltd.
