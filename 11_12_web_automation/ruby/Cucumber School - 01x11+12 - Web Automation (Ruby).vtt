WEBVTT

1
00:00:14.592 --> 00:00:17.920
Welcome to the final lesson in
this series of Cucumber School

2
00:00:18.432 --> 00:00:21.800
Over the series we've tried to cover
all the important techniques

2
00:00:21.800 --> 00:00:27.136
and concepts we think you need to become a
successful behaviour-driven developer

4
00:00:28.00 --> 00:00:31.750
We've taught you how to break down
requirements with example mapping

5
00:00:31.750 --> 00:00:35.750
and how to express those examples
as Gherkin scenarios

6
00:00:35.750 --> 00:00:39.750
We've explained the importance of
keeping your features readable

7
00:00:39.750 --> 00:00:44.544
and shown you how to write great, flexible,
step definitions to help you achieve that goal

8
00:00:45.500 --> 00:00:50.250
We've also explored the difference between
acceptance tests and unit tests

8
00:00:50.250 --> 00:00:54.750
and demonstrated how the outside in
approach to software development works

9
00:00:54.750 --> 00:00:58.200
using both types of tests
to drive out the solution to your

10
00:00:58.200 --> 00:00:59.648
stakeholders problems

11
00:01:01.400 --> 00:01:04.600
One glaring omission from
the story so far however

12
00:01:04.600 --> 00:01:08.500
is that our shouty solution is
nothing more than a domain model

13
00:01:09.150 --> 00:01:12.192
It doesn't have any way for
a user to interact with it

14
00:01:12.600 --> 00:01:15.776
Well, that's all about to change

16
00:01:16.544 --> 00:01:19.600
In this episode, we'll review
the code that's just been written

16
00:01:19.600 --> 00:01:22.900
for the first iteration of
Shouty's web user interface

17
00:01:22.900 --> 00:01:26.784
and show you how to use Selenium WebDriver

18
00:01:27.296 --> 00:01:33.440
a browser automation library to run our
Cucumber scenarios through that user interface

19
00:01:34.464 --> 00:01:38.000
We think it would be irresponsible
to teach you how to use Selenium

19
00:01:38.000 --> 00:01:44.000
without also teaching you about the Agile
testing pyramid and its nemesis

21
00:01:44.000 --> 00:01:45.984
the testing ice cream cone

22
00:01:46.500 --> 00:01:50.200
We've come across too many teams
who have ended up with

23
00:01:50.200 --> 00:01:55.550
miserably slow, unreliable test suites
that cost too much to maintain

24
00:01:55.550 --> 00:01:59.296
because all their Cucumber scenarios
go through the UI

25
00:02:00.064 --> 00:02:02.000
It doesn't have to be this way

26
00:02:02.000 --> 00:02:03.500
and in this episode

27
00:02:03.500 --> 00:02:05.696
we'll show you how to avoid this trap

28
00:02:06.500 --> 00:02:10.000
Let's start by walking you through
the changes that have been happening

28
00:02:10.000 --> 00:02:12.864
in the code base while we've been away

29
00:02:13.500 --> 00:02:17.750
Shouty now has a simple web UI
which displays a form where

29
00:02:17.750 --> 00:02:19.520
a user can shout a message

30
00:02:20.150 --> 00:02:23.000
It won't win any awards for style just yet

31
00:02:23.000 --> 00:02:25.152
but it should be functional at least

32
00:02:26.432 --> 00:02:29.100
We can let Cucumber put the
new web app through its paces

33
00:02:29.100 --> 00:02:34.750
by setting the 'shouty_test_depth'
environment variable to 'web'

33
00:02:34.750 --> 00:02:36.416
when we run Cucumber

34
00:02:37.700 --> 00:02:43.000
This setting causes the scenarios
to be run through the browser via Selenium

35
00:02:43.000 --> 00:02:44.750
and if you watch closely,

35
00:02:44.750 --> 00:02:48.448
you can see the message being typed
into the form as it runs

36
00:02:49.472 --> 00:02:53.500
You can see it's way slower
to run the scenarios via browser

36
00:02:53.500 --> 00:02:55.616
around a minute

37
00:03:21.472 --> 00:03:25.800
Luckily, we still have our original,
much faster version of the acceptance tests

37
00:03:25.800 --> 00:03:27.616
that go directly to the domain model

38
00:03:28.384 --> 00:03:30.432
These run in less than a second

39
00:03:31.200 --> 00:03:35.600
We can run this version by setting
'shouty_test_depth' to something else

40
00:03:35.600 --> 00:03:37.856
or just leaving it out altogether

41
00:03:39.250 --> 00:03:40.700
Nice!

41
00:03:40.700 --> 00:03:43.488
So we have the best of both worlds it seems

42
00:03:44.300 --> 00:03:48.096
Let's have a look at how this
has been implemented in the features

43
00:03:49.500 --> 00:03:54.496
In this world.rb file here
we now have two separate modules being defined

44
00:03:54.752 --> 00:03:58.750
Our original ShoutyWorld has been
renamed to DomainWorld

45
00:03:58.750 --> 00:04:01.664
and a new WebWorld has been added

46
00:04:02.176 --> 00:04:06.350
WebWorld has exactly the same
methods as the original DomainWorld

47
00:04:06.350 --> 00:04:08.832
but the implementation is quite different

48
00:04:09.856 --> 00:04:11.500
In the sean_shout method

48
00:04:11.500 --> 00:04:16.400
rather than calling the Person domain object
directly to shout the message

49
00:04:16.400 --> 00:04:21.300
the WebWorld calls this visit method
to open the homepage as Sean

50
00:04:21.300 --> 00:04:24.000
then posts the message into
the shout form

51
00:04:25.000 --> 00:04:29.823
Where have these new methods
visit, fill_in, and click_button come from?

52
00:04:30.847 --> 00:04:32.800
They're provided by Capybara

53
00:04:32.800 --> 00:04:36.300
which is a delightful Ruby library
that wraps Selenium WebDriver

53
00:04:36.300 --> 00:04:38.527
in a user-friendly package

54
00:04:39.039 --> 00:04:41.750
I know you're almost drowning
in buzzwords at this point

55
00:04:41.750 --> 00:04:45.000
Don't worry- we'll clear up this in a moment

55
00:04:45.000 --> 00:04:46.800
Let's continue with the tour

56
00:04:48.150 --> 00:04:52.607
Down here, we examine the value of
the shouty_test_depth environment variable

57
00:04:52.863 --> 00:04:54.250
If it's 'web'

58
00:04:54.250 --> 00:04:58.751
we load Capybara, configure it for Selenium,
tell it how to boot up our web app

59
00:04:59.263 --> 00:05:04.127
then finally, tell Cucumber to use
the WebWorld in the step definitions

60
00:05:05.151 --> 00:05:09.500
The alternative, of course,
is just to use the DomainWorld as normal

61
00:05:09.500 --> 00:05:13.599
Let's walk through what happens
when a scenario runs using the WebWorld

62
00:05:14.200 --> 00:05:18.500
When Cucumber runs the
'Sean shouts, "Free bagels!"' step

63
00:05:18.500 --> 00:05:22.559
it searches for the corresponding
step definition and executes it

64
00:05:23.350 --> 00:05:28.750
Now, the code in that step definition
calls the sean_shout method on the World

65
00:05:28.750 --> 00:05:34.079
which in turn calls the visit method
on Capybara to open the homepage as Sean

66
00:05:34.847 --> 00:05:39.250
Capybara will now tell Selenium WebDriver
to open a browser at that URL

67
00:05:39.250 --> 00:05:43.000
Selenium tells Firefox what it needs to do

68
00:05:43.000 --> 00:05:48.000
and when the browser opens that URL,
our website will get a request for the page

69
00:05:48.000 --> 00:05:51.487
we render the page on the server
and the browser displays it

70
00:05:52.250 --> 00:05:58.000
Next, the World asks Capybara to fill out
and submit the shout form

72
00:05:58.000 --> 00:06:03.519
which causes it to give instructions to Selenium,
which in turn causes button clicks in the browser

73
00:06:04.287 --> 00:06:05.750
The form is submitted

74
00:06:05.750 --> 00:06:09.663
the server calls the core domain
to broadcast a shout

76
00:06:14.527 --> 00:06:16.000
In contrast

77
00:06:16.000 --> 00:06:20.159
the DomainWorld implementation of sean_shout
calls the domain model directly.

78
00:06:21.183 --> 00:06:25.535
Notice this is exactly the same code
as the web server uses

79
00:06:27.300  --> 00:06:31.750
Using multiple worlds like this
allows us to choose the strategy

80
00:06:31.750 --> 00:06:33.727
for automating our application

81
00:06:34.495 --> 00:06:37.500
The strategy that talks directly
to the core domain model

81
00:06:37.500 --> 00:06:40.000
gives us fast feedback
and lets us test where the

82
00:06:40.000 --> 00:06:42.943
heart of the application's
behaviour is implemented

83
00:06:43.711 --> 00:06:46.750
We've now added a second strategy
that allows us to prove this behavior

83
00:06:46.750 --> 00:06:49.855
still works when presented via the web UI

84
00:06:50.879 --> 00:06:52.927
You might be wondering why we need both?

85
00:06:53.439 --> 00:06:57.279
Why didn't we just start driving our way in
from the web UI in the beginning?

86
00:06:59.071 --> 00:07:04.200
We found that focusing on driving out
a domain model from our scenarios first

87
00:07:04.200 --> 00:07:07.100
modelling by example

88
00:07:07.100 --> 00:07:11.615
gives us fast feedback about
our understanding of new problem domains

89
00:07:12.127 --> 00:07:15.100
We don't get distracted by
solution domain complexities like

89
00:07:15.100 --> 00:07:18.400
web servers, HTML, and so on

90
00:07:18.400 --> 00:07:21.855
while we're still just trying to understand
the core of the problem

91
00:07:23.135 --> 00:07:29.279
In the long run, we also find that
staying focused on the core domain

92
00:07:27.000 --> 00:07:30.815
helps us build scenarios that are
more stable over time

93
00:07:31.839 --> 00:07:34.750
User interfaces tend to change
a lot more often than

93
00:07:34.750 --> 00:07:37.471
the core business rules of the domain

94
00:07:39.263 --> 00:07:42.000
Building scenarios that make sense
even without a user interface

95
00:07:43.000 --> 00:07:46.400
also helps us to avoid
our tests from becoming too

96
00:07:46.400 --> 00:07:47.711
Imperative

97
00:07:48.735 --> 00:07:52.100
Most teams who write and run their cukes
against the user interface

98
00:07:52.100 --> 00:07:58.100
end it with a lot of incidental detail
in their scenarios about the UI interaction

99
00:07:58.100 --> 00:07:59.743
Solution domain stuff

100
00:08:00.767 --> 00:08:03.100
These scenarios are poor documentation

101
00:08:03.600 --> 00:08:07.200
They're too busy talking about
how the user performs a task

101
00:08:07.200 --> 00:08:11.100
rather than what the user is trying to achieve

102
00:08:11.100 --> 00:08:12.400
For example

103
00:08:12.400 --> 00:08:15.103
we might have written the scenario like this instead

104
00:08:18.700 --> 00:08:21.759
This scenario doesn't illustrate the behaviour very well

105
00:08:22.400 --> 00:08:26.000
If you didn't know anything about Shouty
and were trying to understand it

106
00:08:26.000 --> 00:08:29.600
through the examples written like this
you'd have a tough time

107
00:08:30.300 --> 00:08:32.511
It makes for lousy documentation

108
00:08:34.303 --> 00:08:37.000
Notice how the language used in this scenario

109
00:08:37.000 --> 00:08:39.850
the URLs, the CSS selectors

110
00:08:39.850 --> 00:08:42.500
even the filling in fields
and clicking of buttons

110
00:08:42.500 --> 00:08:46.079
is from the solution domain,
not the problem domain

111
00:08:47.000 --> 00:08:50.943
It tells you nothing about
your team's ubiquitous language

112
00:08:52.600 --> 00:08:55.039
Finally, this scenario is brittle

114
00:08:55.400 --> 00:08:59.850
If you need to change the details
of the interaction for sending a shout

115
00:08:59.850 --> 00:09:01.750
such as the way you authenticate

116
00:09:01.750 --> 00:09:05.535
you'd need to come back
and change every scenario that involves shouting

117
00:09:06.000 --> 00:09:08.351
By pushing the how down

118
00:09:08.863 --> 00:09:12.447
your scenarios will remain truer
for longer

120
00:09:13.471 --> 00:09:16.800
The opposite of the imperative style,
where we express the scenarios

120
00:09:16.800 --> 00:09:19.800
using problem domain language is known as a

121
00:09:19.800 --> 00:09:21.407
Declarative Style

122
00:09:21.919 --> 00:09:26.000
In this style, we try to describe
what the user is trying to achieve

122
00:09:26.000 --> 00:09:28.063
rather than how they do it

123
00:09:29.400 --> 00:09:33.350
Thanks to the declarative style
we've been using through the rest of the series

124
00:09:33.350 --> 00:09:36.500
we were able to easily swap in a
different strategy for automating

125
00:09:36.500 --> 00:09:40.863
our application through the web
without changing our specifications

126
00:09:41.887 --> 00:09:44.000
If there are other interfaces to our
application

126
00:09:44.000 --> 00:09:47.600
like a rest API or a mobile app

127
00:09:47.600 --> 00:09:51.000
we can continue to use this pattern,
adding new strategies

128
00:09:51.000 --> 00:09:54.687
that run our scenarios through
these new layers of the stack

129
00:09:55.800 --> 00:10:02.367
Remember, each of these strategies uses
exactly the same scenarios and step definitions

131
00:10:03.135 --> 00:10:09.000
This means the investment you put into
writing your scenarios pays back over and over

132
00:10:09.000 --> 00:10:11.800
as you reuse them to validate
the behaviour of the application

132
00:10:11.800 --> 00:10:13.631
from these different perspectives

133
00:10:14.399 --> 00:10:18.500
This is a major advantage of having
pushed the details of how Sean shouts

133
00:10:18.500 --> 00:10:20.031
down into a helper method

134
00:10:20.799 --> 00:10:23.000
If this detail was still up
in the step definition

135
00:10:23.000 --> 00:10:28.500
or worse, in the scenario itself,
we wouldn't have this flexibility

136
00:10:29.500 --> 00:10:33.200
In general, the structure emerging
in our application and test code

136
00:10:33.200 --> 00:10:36.700
is called a ports and adapters architecture, or

137
00:10:36.700 --> 00:10:38.719
Hexagonal Architecture

138
00:10:39.487 --> 00:10:42.350
You can think of ports and adapters
as a direct analogy

138
00:10:42.350 --> 00:10:45.119
to physical devices with plugs and sockets

139
00:10:45.887 --> 00:10:48.300
For example,
the HDMI port on this laptop

140
00:10:48.300 --> 00:10:52.799
lets me plug in any kind of display
that also has a HDMI port

141
00:10:53.567 --> 00:10:58.175
If I need to use a VGA display,
I can use an adapter between the two

142
00:10:59.711 --> 00:11:01.900
In a hexagonal architecture

143
00:11:01.900 --> 00:11:05.087
the inner hexagon contains
your core business logic

144
00:11:06.000 --> 00:11:10.250
This is where the if statements that
deliver the most value to your stakeholders

144
00:11:10.250 --> 00:11:11.100
should live

145
00:11:12.255 --> 00:11:14.900
The inner hexagon knows nothing about
the outside world:

145
00:11:14.900 --> 00:11:18.550
your web servers, your databases,
your email sending service

146
00:11:18.550 --> 00:11:20.447
or your enterprise message bus

147
00:11:21.215 --> 00:11:23.263
It's pure business logic

148
00:11:24.543 --> 00:11:28.639
We expose this core behavior via one or more ports

149
00:11:29.663 --> 00:11:33.503
A port is really just a protocol,
an API if you like

150
00:11:34.271 --> 00:11:38.150
Any component who understands that protocol
can then plug in and interact

150
00:11:38.150 --> 00:11:40.415
with the core through the port

151
00:11:41.439 --> 00:11:43.743
We call that component an adapter

152
00:11:43.999 --> 00:11:48.863
It's the adapter's job to expose
the core domain logic to the outside world

153
00:11:49.887 --> 00:11:52.800
In Shouty, there's just one port

154
00:11:52.800 --> 00:11:57.311
the API to our domain model
made up of the Person and Network classes

155
00:11:58.000 --> 00:12:01.500
We've plugged in two different adapters
to this little port:

156
00:12:01.500 --> 00:12:02.500
the WebApp

157
00:12:02.500 --> 00:12:05.150
which exposes Shouty's core domain
over the web

157
00:12:05.150 --> 00:12:08.831
for users (or Selenium WebDriver)
to interact with

158
00:12:09.500 --> 00:12:11.500
And the DomainWorld

159
00:12:11.500 --> 00:12:14.463
which lets Cucumber
drive the application directly

160
00:12:15.487 --> 00:12:18.559
Both are clients of the same API
---
161
00:12:20.863 --> 00:12:25.727
The hexagonal architecture
is a terrific fit

for teams who care about testability

162
00:12:25.983 --> 00:12:32.127
In fact, it was invented precisely
to allow for testability

163
00:12:32.383 --> 00:12:33.919
back in the days when thick client GUIs weres
impossible to automate

164
00:12:34.431 --> 00:12:40.575
By separating the core domain logic
from the GUI

165
00:12:40.831 --> 00:12:42.879
these TDD pioneers were able to plug
their tests into the same port is the GUI

166
00:12:43.135 --> 00:12:45.951
and still test most of
the application's behaviour

167
00:12:47.487 --> 00:12:50.559
If you have the discipline
to keep your code separated like this

168
00:12:50.815 --> 00:12:56.959
you benefit by being able to
run the tests

against the most business-valuable
lines of code in your codebase

169
00:12:57.215 --> 00:12:57.983
the core domain

170
00:12:58.239 --> 00:13:00.543
in the shortest amount of time

171
00:13:01.823 --> 00:13:05.151
Tests that hit pure business logic
can run lightning fast

172
00:13:05.407 --> 00:13:11.039
meaning it's cheap to get
really thorough feedback

about whether that logic is behaving correctly

173
00:13:12.831 --> 00:13:14.367
Let's get back to the code

174
00:13:15.135 --> 00:13:19.487
To give us a way to test the app manually,
the Shouty developers have kindly added this

175
00:13:19.743 --> 00:13:21.535
config.ru file

176
00:13:21.791 --> 00:13:25.631
which starts the web server pre-configured
with some familiar test dates

177
00:13:26.655 --> 00:13:30.751
This means we're able to test
the web app without having

178
00:13:31.263 --> 00:13:32.799
to create accounts for people
a future we don't have yet!


179
00:13:34.079 --> 00:13:37.407
So we should be able to
open our browser tab as Sean

180
00:13:37.919 --> 00:13:39.455
then another tab as Lucy

181
00:13:40.223 --> 00:13:42.015
send a shout from Sean

182
00:13:42.271 --> 00:13:46.367
refresh Lucy's page and see- 

wait a minute!

183
00:13:46.879 --> 00:13:48.415
Where's Sean Shout?

184
00:13:49.695 --> 00:13:50.463
This is odd-

185
00:13:50.975 --> 00:13:53.023
The scenario is passing

186
00:13:53.279 --> 00:13:56.095
but there's nothing appearing on Lucy's page

187
00:13:57.119 --> 00:13:58.399
What's going on?

188
00:13:59.423 --> 00:14:03.775
The answer lies in the implementation of our Then step

189
00:14:05.055 --> 00:14:11.199
Reading it, we can see that the step definition is going directly to the domain model to discover the messages

190
00:14:11.455 --> 00:14:12.479
that Lucy has heard

191
00:14:13.759 --> 00:14:15.551
This should not have been a surprise to us

192
00:14:16.063 --> 00:14:17.343
it's always been that way

193
00:14:18.111 --> 00:14:20.927
but since our When step now hits the UI

194
00:14:21.183 --> 00:14:23.487
we would expect this Then step

195
00:14:23.743 --> 00:14:25.791
to also adopt the same strategy

196
00:14:27.327 --> 00:14:30.911
When you start to mix different depths of testing as we’re doing here

197
00:14:31.423 --> 00:14:37.311
a good rule of thumb is to keep the depth of your When and Then steps consistent

198
00:14:38.335 --> 00:14:44.479
It’s often advisable to bypass layers and reach down deeper 

199
00:14:44.735 --> 00:14:45.247
into the stack to set up state in the Given steps

200
00:14:46.015 --> 00:14:48.575
but if we carry out an action via the UI

201
00:14:49.343 --> 00:14:53.695
the outcome check in the Then step
should also be done through the UI

203
00:14:56.255 --> 00:15:00.351
Let’s remedy this situation by pushing the code in this step down

204
00:15:00.607 --> 00:15:01.887
into a helper method

205
00:15:02.655 --> 00:15:07.007
Then we’ll be able to have two different strategies
for checking the messages that a user has heard

206
00:15:08.287 --> 00:15:12.895
Once we have a failing test for the web strategy, we can drive out the behaviour

207
00:15:13.407 --> 00:15:15.967
in the UI to display the user’s messages

208
00:15:16.991 --> 00:15:19.807
We’ll focus on a single scenario while we do this work

209
00:15:20.831 --> 00:15:23.903
Once we’ve got that one passing to our satisfaction

210
00:15:24.159 --> 00:15:27.231
we can apply the same change across the rest of the scenarios

211
00:15:28.511 --> 00:15:33.631
This very basic scenario, where Lucy hears Sean, is a good place to start

212
00:15:35.423 --> 00:15:38.495
Let's extract a method, messages heard by, from the body of the step definition

213
00:15:38.751 --> 00:15:40.031
and put it on our

214
00:15:40.287 --> 00:15:41.311
DomainWorld

215
00:15:49.247 --> 00:15:50.783
That scenario is still passing, good

216
00:15:53.855 --> 00:15:56.159
Now, when we run it through the web

217
00:15:56.415 --> 00:15:58.975
we’re shown we need to add that method to the WebWorld

218
00:16:00.767 --> 00:16:02.815
How will we fetch the messages heard?

219
00:16:03.583 --> 00:16:07.679
The first thing we’ll need to do is log in, to make sure we’re reading the messages for the correct user

220
00:16:08.447 --> 00:16:10.751
So we can re-use this helper method we’ve already built

221
00:16:11.775 --> 00:16:15.615
Now we’ll need to scrape the messages off the HTML page

222
00:16:16.127 --> 00:16:19.967
Remember we’re going test-first here, so we don’t have this markup yet

223
00:16:20.735 --> 00:16:22.015
That's not a problem

224
00:16:22.271 --> 00:16:25.343
we can use the test to help us design what the markup should look like

225
00:16:26.879 --> 00:16:31.487
Let’s assume that each message will be in an element with a message class on it

226
00:16:32.255 --> 00:16:35.839
We can ask Capybara to give us all
the elements with that class

227
00:16:36.863 --> 00:16:43.007
That gives us a list of Capybara HTML nodes which

228
00:16:43.263 --> 00:16:43.775
we can then transform into
a list of their text content

229
00:16:44.799 --> 00:16:46.335
Let's watch this test fail

230
00:16:50.175 --> 00:16:51.455
That looks OK.

231
00:16:52.223 --> 00:16:54.527
Let's play fake it till you make it

232
00:16:54.783 --> 00:16:57.599
just to check this assertion is doing the right thing

233
00:16:58.111 --> 00:17:01.951
We’ll hard-code the HTML we want into the template, here

234
00:17:04.511 --> 00:17:07.583
This gives us a chance to talk with our designer about the markup

235
00:17:08.095 --> 00:17:12.959
We go over for a chat and he loves it,
so we can press on!

238
00:17:15.007 --> 00:17:18.591
The next step is to make the HTML template dynamic

239
00:17:18.847 --> 00:17:22.687
and have it display the list of
actual messages heard by the user

240
00:17:23.455 --> 00:17:29.599
We could continue using the
Cucumber scenario to drive this out 

but it would be better to zoom in and focus

241
00:17:29.855 --> 00:17:31.903
on some unit tests for the web app now

242
00:17:32.927 --> 00:17:39.071
That way, if this behaviour ever
slips loose in the future

243
00:17:39.327 --> 00:17:40.351
there will be a unit test pointing us
to exactly where we need to go to fix it

244
00:17:41.631 --> 00:17:45.471
Luckily the web app has already been built with some unit tests around it

245
00:17:47.519 --> 00:17:51.615
These tests load the Sinatra web app in isolation

246
00:17:51.871 --> 00:17:55.455
passing in a hash of people that just contains test doubles

247
00:17:56.223 --> 00:18:02.367
We could have used real instances from our domain model,
but as we explained in the last episode

248
00:18:02.623 --> 00:18:07.231
using test doubles helps us to see the protocol on the port between the web app adapter and our core domain

249
00:18:09.023 --> 00:18:12.863
We use a library called rack-test to make requests to the web app

250
00:18:13.375 --> 00:18:19.519
and load the response into a Capybara HTML document, so we can make queries and assertions about the HTML

251
00:18:19.775 --> 00:18:21.055
in the response if we want to

252
00:18:22.591 --> 00:18:24.639
The tests are organised by request

253
00:18:25.151 --> 00:18:29.503
so that when we run them, we get some
nice documentation about how the app behaves

254
00:18:30.783 --> 00:18:36.927
We need a new test for the GET request 

which simulates the situation where
Lucy has heard a couple of messages

255
00:18:41.791 --> 00:18:43.583
and views her homepage

256
00:18:44.607 --> 00:18:48.959
We’d expect to be able to find the message text in each of the message elements

257
00:18:51.775 --> 00:18:53.055
When we run this

258
00:18:53.311 --> 00:18:56.895
it fails because we’re just hard-coding
the message at the moment

259
00:18:57.407 --> 00:18:59.199
Let's TDD our solution

260
00:19:01.247 --> 00:19:07.391
If you’d like to try this yourself,
just pause the video here

and see if you can figure out what
to do next, before we show you

261
00:19:10.463 --> 00:19:16.095
Starting in the template, we can look
for a local variable

let’s call it messages heard

262
00:19:16.351 --> 00:19:17.887
and iterate over it

263
00:19:18.399 --> 00:19:20.959
For each message, we’ll write a message element

There. 

264
00:19:28.127 --> 00:19:31.455
Now we need to set up messages Hood variable for the template

265
00:19:32.223 --> 00:19:35.039
Now we need to set that
messages heard variable for the template

266
00:19:36.319 --> 00:19:38.367
We need to get the messages heard for the user

267
00:19:38.623 --> 00:19:44.255
which we can fetch from the @people hash,
using the name param as the key to find them

268
00:19:45.279 --> 00:19:51.167
Now we pass the messages heard through
to the view template in this locals hash

269
00:19:52.703 --> 00:19:53.983
Let's give that a try

270
00:20:13.951 --> 00:20:14.719
Great!

271
00:20:15.999 --> 00:20:17.791
Suddenly everything is green

272
00:20:19.327 --> 00:20:24.191
Try a quick manual test for yourself,
creating a couple of tabs as Sean and Lucy

273
00:20:24.447 --> 00:20:27.007
and satisfy yourself that it’s working now

274
00:20:28.031 --> 00:20:33.151
Now that we’ve proved our messages_heard_by method
works for both domain and web strategies

275
00:20:33.407 --> 00:20:39.551
let’s use that method in all the step definitions,
so that every scenario that checks for messages heard

276
00:20:39.807 --> 00:20:42.111
will do that check in a consistent way

277
00:20:43.135 --> 00:20:49.279
This is just a matter of finding each call
to ask a Person domain object for messages_heard

278
00:20:49.535 --> 00:20:51.071
and converting it to use our new helper method instead

279
00:20:54.399 --> 00:20:56.959
Let's run all the scenarios in the shout feature

280
00:21:01.311 --> 00:21:01.823
Great

281
00:21:02.335 --> 00:21:03.871
it looks like we're done

282
00:21:05.151 --> 00:21:06.687
If we look at the other feature

283
00:21:06.943 --> 00:21:12.319
premium accounts, we can see that there’s
a similar problem to the one we’ve just resolved

284
00:21:13.087 --> 00:21:14.367
This last step

285
00:21:14.623 --> 00:21:17.440
'Then Sean should have n credits'

286
00:21:17.952 --> 00:21:24.096
goes direct to the domain model to check Sean’s credits,
rather than having that extra layer of indirection

287
00:21:24.352 --> 00:21:27.424
that would allow us to use a domain
or a web strategy for the check

288
00:21:28.448 --> 00:21:34.592
It will be useful practice for you to go through
and apply exactly what we just did to this step definition

289
00:21:35.616 --> 00:21:37.920
We'll leave that as an exercise for you

290
00:21:40.224 --> 00:21:42.272
Let's fast-forward to the point where this is done

291
00:21:43.808 --> 00:21:49.952
Now we can run all of our scenarios at both levels

292
00:21:50.208 --> 00:21:50.976
against the domain, and against the web UI. 

293
00:21:52.256 --> 00:21:53.792
This is awesome!

294
00:21:55.328 --> 00:21:56.096
Isn't it?

295
00:21:56.864 --> 00:22:00.448
We've talked a lot about the benefits of automated testing in this series

296
00:22:00.960 --> 00:22:05.056
but let’s consider the flip side for a moment,
and look at the costs

297
00:22:06.592 --> 00:22:10.176
Every automated test in your system comes at a cost

298
00:22:10.944 --> 00:22:13.504
You have the cost of writing it in the first place

299
00:22:14.016 --> 00:22:16.832
the cost of waiting for it to run each time

300
00:22:17.344 --> 00:22:21.696
the cost of changing it for the
desired behaviour of the application changes

301
00:22:22.208 --> 00:22:26.304
and the cost of debugging it when it fails for no good reason

302
00:22:27.840 --> 00:22:33.472
When the majority of your tests hit the application through the user interface, you get a great benefit

303
00:22:33.728 --> 00:22:37.824
rom knowing that each scenario is using the system exactly as a user would

304
00:22:38.848 --> 00:22:42.432
Yet the downside is that these tests are much slower to run

305
00:22:42.944 --> 00:22:44.736
and are often also much less reliable

306
00:22:46.272 --> 00:22:51.904
A well-known metaphor to help you think about this problem is the agile testing pyramid

307
00:22:52.928 --> 00:22:57.280
At the base of the pyramid,
you have a large number of unit tests

308
00:22:57.792 --> 00:23:03.936
shallow tests that directly hit isolated,
individual classes and modules in your solution

309
00:23:05.728 --> 00:23:08.288
The pyramid gets narrower as you go up

310
00:23:08.544 --> 00:23:12.128
indicating that as the depth of tests increases

311
00:23:12.384 --> 00:23:14.176
the less of them you should have

312
00:23:14.688 --> 00:23:20.064
At the very top of the pyramid, where the tests that go right through the whole application stack

313
00:23:20.832 --> 00:23:22.368
You want as few as possible

314
00:23:23.392 --> 00:23:26.720
Just enough to give you confidence the thing is working

315
00:23:28.512 --> 00:23:31.328
When you drive most of your behaviour through the GUI

316
00:23:31.584 --> 00:23:33.120
you end up with the opposite

317
00:23:33.376 --> 00:23:36.192
more of a testing ice cream cone

318
00:23:36.960 --> 00:23:39.776
I love an ice cream on a hot summer’s day

319
00:23:40.032 --> 00:23:42.336
but when your test suite looks like this

320
00:23:42.592 --> 00:23:48.736
you’re waiting hours for test results,
and there are generally at least

321
00:23:48.992 --> 00:23:50.272
one or two random failures in every build

322
00:23:52.576 --> 00:23:55.904
Although we have the choice to run every Shouty scenario through the GUI

323
00:23:56.160 --> 00:24:00.256
the agile testing pyramid tells us that would be a bad idea

324
00:24:01.536 --> 00:24:07.424
We need to select a few representative or key examples to run through the web UI

325
00:24:07.680 --> 00:24:09.728
and run the rest through the domain

326
00:24:11.008 --> 00:24:13.056
How do we choose those key examples?

327
00:24:14.592 --> 00:24:17.408
Let’s try and think about what could possibly go wrong

328
00:24:18.176 --> 00:24:22.784
We want to identify the minimum number of scenarios that would give us confidence the system is working

329
00:24:23.552 --> 00:24:28.928
Remember both our core domain and our web server are protected by their own unit tests

330
00:24:29.184 --> 00:24:32.000
so we just need a few checks for basic correctness.

331
00:24:32.512 --> 00:24:35.328
Would it be enough to just test this scenario

332
00:24:35.584 --> 00:24:37.632
the one where the listener is within range?

333
00:24:38.912 --> 00:24:41.728
If we did that, what could possibly go wrong?

334
00:24:43.264 --> 00:24:49.408
With our tester’s hat on, we can imagine a bug where the web server’s template didn’t render multiple messages

335
00:24:50.176 --> 00:24:52.224
this scenario only works for one

336
00:24:53.248 --> 00:24:57.088
So we could add this scenario,
the one where there are two shouts

337
00:24:57.856 --> 00:25:00.672
Yet we’d easily catch that bug in manual testing

338
00:25:00.928 --> 00:25:03.744
and could then pin it down with
a unit test on the web server

339
00:25:05.024 --> 00:25:08.352
So we don’t need to run this as a full-stack test every time

340
00:25:09.120 --> 00:25:10.144
In fact

341
00:25:10.656 --> 00:25:12.960
to do so would be wasteful

342
00:25:14.752 --> 00:25:18.336
How about the scenario about the listener being out of range?

343
00:25:19.104 --> 00:25:21.920
If we skip that in our web-depth Cucumber run

344
00:25:22.688 --> 00:25:25.504
would we leave ourselves vulnerable to a dangerous bug?

345
00:25:27.040 --> 00:25:33.184
Well, it’s true that if people heard messages
that were not meant for them

it could make us look pretty bad

346
00:25:34.208 --> 00:25:36.256
How likely is this to happen?

347
00:25:37.024 --> 00:25:39.072
That logic is all in the core domain

348
00:25:39.584 --> 00:25:43.168
the web server just renders the messages returned by the core

349
00:25:43.936 --> 00:25:47.520
So there’s almost a zero risk of
this bug ever leaking out

350
00:25:48.288 --> 00:25:51.872
Again, a full-stack test for this
behaviour would be wasteful

351
00:25:54.432 --> 00:26:00.576
Although the same goes for the logic about a long message, we know that there’s potential for there to be bugs in the interaction

352
00:26:00.832 --> 00:26:03.136
of the UI for longer messages

353
00:26:03.392 --> 00:26:05.440
so it makes sense for us to run this one

354
00:26:06.208 --> 00:26:08.512
Let’s mark it up as @high-risk

355
00:26:09.024 --> 00:26:13.120
and mark the one where the listener is
within range as @high-impact

356
00:26:13.888 --> 00:26:15.680
We’ll explain those terms in a moment

357
00:26:16.960 --> 00:26:23.872
Now we can run the tests at the top of our pyramid
using those tags and the web test-depth setting

359
00:26:24.640 --> 00:26:29.504
Now we have three different levels of tests
in our pyramid that we want to run to check our code

360
00:26:29.760 --> 00:26:31.040
The unit tests

361
00:26:31.296 --> 00:26:36.672
the core domain acceptance tests,
and the key examples running as full-stack tests

362
00:26:37.696 --> 00:26:43.072
Let's set up a rake task to run all
of these tests for us with a single command

363
00:26:44.608 --> 00:26:47.168
First we’ll create a new Rakefile

364
00:26:48.192 --> 00:26:51.520
We’ll add a default task that depends on three tasks

365
00:26:52.032 --> 00:26:57.408
unit test, core acceptance tests,
and web acceptance tests

368
00:26:58.944 --> 00:27:00.736
Unit tests is easy to implement

369
00:27:00.992 --> 00:27:02.784
We just shell out to RSpec

370
00:27:04.320 --> 00:27:06.368
Core acceptance tests is very similar

371
00:27:06.880 --> 00:27:08.672
but we shell out to cucumber instead

372
00:27:09.952 --> 00:27:16.096
Now for the web acceptance tests
we just need to shell out to Cucumber

373
00:27:16.352 --> 00:27:17.632
but this time set the
shouty_test_depth environment variable

374
00:27:17.888 --> 00:27:20.192
and pass the tags configuration switch

There

375
00:27:20.704 --> 00:27:23.264
Now when we run `rake` from the command-line

376
00:27:23.520 --> 00:27:26.080
it runs all three layers of our testing pyramid

377
00:27:26.336 --> 00:27:27.872
starting from the bottom up

378
00:27:33.504 --> 00:27:34.528
One last thing

379
00:27:35.296 --> 00:27:39.904
When we automate web pages, we need to
refer to user interface elements and actions

380
00:27:40.160 --> 00:27:42.720
buttons, links, text, clicks, etc

381
00:27:43.488 --> 00:27:48.864
This is solution domain jargon
we’ve managed to keep out of our scenarios

and that’s good!

382
00:27:49.632 --> 00:27:51.168
But it has to go somewhere

383
00:27:52.704 --> 00:27:58.848
On larger projects, it becomes useful
to create abstractions called

page objects to represent
the things being filled in

384
00:27:59.104 --> 00:28:00.640
clicked, and examined for content

385
00:28:01.152 --> 00:28:07.296
For example, we might have a homepage object with a method called shout that encapsulated the calls

386
00:28:07.552 --> 00:28:09.856
to interact with the elements on the web page

387
00:28:10.368 --> 00:28:12.672
This allows you to easily reuse code

388
00:28:13.184 --> 00:28:14.976
and keep it easy to read

389
00:28:16.000 --> 00:28:22.144
You can easily build page objects on your own, but if you’re feeling lazy there are a few libraries that reduce the amount of boilerplate code

390
00:28:22.400 --> 00:28:23.168
you need to write

391
00:28:23.424 --> 00:28:28.032
Jeff “Cheezy” Morgan’s page-objects gem
is a popular choice.

392
00:28:29.568 --> 00:28:34.944
The page objects pattern is a great fit for keeping your web automation code tidy

393
00:28:35.200 --> 00:28:42.368
but we strongly recommend that you try to push as many of your tests down the pyramid first

395
00:28:43.392 --> 00:28:48.512
You can use page objects together with the hexagonal architecture pattern we’ve shown you in this episode

396
00:28:48.768 --> 00:28:51.328
 so that when you do need to hit the web UI

397
00:28:51.840 --> 00:28:54.144
you do that through neat and tidy code

398
00:28:54.912 --> 00:28:57.728
That's it kids, school's out!

400
00:28:57.984 --> 00:29:00.800
Time to step out into the real world

401
00:29:02.080 --> 00:29:06.944
This has been an intense episode, and we’ve thrown a lot of new concepts at you

402
00:29:07.712 --> 00:29:12.832
the hexagonal architecture, the strategy pattern and the agile testing pyramid

403
00:29:14.112 --> 00:29:20.256
Please take time to watch this video over a few times until you understand these concepts

404
00:29:20.512 --> 00:29:23.072
and study the exercises and reflection questions

405
00:29:24.096 --> 00:29:29.984
We want you to remember that acceptance tests
don’t have to be full-stack tests

406
00:29:31.520 --> 00:29:33.312
In fact, it’s often a mistake if they are

407
00:29:34.848 --> 00:29:40.224
Don’t fall into the trap of building another yet testing ice cream cone for your project

408
00:29:40.992 --> 00:29:47.136
Have developers and testers work side-by-side to maximise the value you get from your testing

409
00:29:47.392 --> 00:29:52.256
investment by pushing as many tests
as you can down to the lowest level

411
00:29:53.280 --> 00:29:59.424
The responsibility for the health and wellbeing
of the world’s Cucumber suites rests with you now

412
00:30:00.448 --> 00:30:03.008
Use your knowledge wisely!

413
00:30:05.824 --> 00:30:10.432
If you remember one thing from the video series,
remember this:

415
00:30:11.456 --> 00:30:14.528
the software you write
is just a model-

417
00:30:15.552 --> 00:30:19.392
A model of your team's understanding
of the problem domain

418
00:30:20.672 --> 00:30:22.976
The better that understanding is

419
00:30:23.232 --> 00:30:25.280
the better the software will be

420
00:30:26.304 --> 00:30:30.400
Put your effort into understanding the problem together,

421
00:30:30.912 --> 00:30:34.240
and the software will take care of itself

423
00:30:36.544 --> 00:30:38.848
Goodbye from all of us on Cucumber School

424
00:30:39.360 --> 00:30:40.896
and have fun out there!

424
00:30:43.000 --> 00:30:46.000
Captions created by Jayson Smith for Cucumber Ltd.