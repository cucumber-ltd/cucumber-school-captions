1
00:00:14,660 --> 00:00:17,920
Welcome to the final lesson in
this series of Cucumber School!

2
00:00:18,480 --> 00:00:21,700
Over the series we've tried to cover
all the important techniques

3
00:00:21,700 --> 00:00:27,140
and concepts we think you need to become a
successful behaviour-driven developer

4
00:00:28,140 --> 00:00:32,080
We've taught you how to break down
requirements with example mapping

5
00:00:32,080 --> 00:00:35,580
and how to express those examples
as Gherkin scenarios

6
00:00:36,100 --> 00:00:39,960
We've explained the importance of
keeping your features readable

7
00:00:39,960 --> 00:00:44,580
and shown you how to write great, flexible
step definitions to help you achieve that goal

8
00:00:45,820 --> 00:00:50,780
We've also explored the difference between
acceptance tests and unit tests

9
00:00:50,780 --> 00:00:55,460
and demonstrated how the outside in
approach to software development works

10
00:00:55,460 --> 00:00:58,100
using both types of tests
to drive out the solution to your

11
00:00:58,100 --> 00:00:59,640
stakeholders' problems

12
00:01:01,640 --> 00:01:04,820
One glaring omission from
the story so far however

13
00:01:04,820 --> 00:01:08,340
is that our Shouty solution is
nothing more than a domain model

14
00:01:09,320 --> 00:01:12,280
It doesn't have any way for
a user to interact with it

15
00:01:12,960 --> 00:01:15,780
Well, that's all about to change

16
00:01:16,540 --> 00:01:19,960
In this episode, we'll review the code
that's just been written

17
00:01:19,960 --> 00:01:23,740
for the first iteration of
Shouty's web user interface

18
00:01:23,740 --> 00:01:27,420
and show you how to use Selenium WebDriver

19
00:01:27,420 --> 00:01:33,440
a browser automation library to run our
Cucumber scenarios through that user interface

20
00:01:34,460 --> 00:01:38,520
We think it would be irresponsible
to teach you how to use Selenium

21
00:01:38,520 --> 00:01:44,060
without also teaching you about the Agile
testing pyramid and its nemesis

22
00:01:44,060 --> 00:01:45,980
the testing ice cream cone

23
00:01:46,760 --> 00:01:50,120
We've come across too many teams
who have ended up with

24
00:01:50,120 --> 00:01:55,820
miserably slow, unreliable test suites
that cost too much to maintain

25
00:01:55,820 --> 00:01:59,300
because all their Cucumber scenarios
go through the UI

26
00:02:00,060 --> 00:02:03,600
It doesn't have to be this way
and in this episode

27
00:02:03,600 --> 00:02:05,760
we'll show you how to avoid this trap

28
00:02:06,760 --> 00:02:10,560
Let's start by walking you through
the changes that have been happening

29
00:02:10,560 --> 00:02:13,060
in the code base while we've been away

30
00:02:13,640 --> 00:02:16,480
Shouty now has a simple web UI

31
00:02:16,480 --> 00:02:19,340
which displays a form
where a user can shout a message

32
00:02:20,440 --> 00:02:25,000
It won't win any awards for style just yet
but it should be functional at least

33
00:02:26,300 --> 00:02:29,780
We can let Cucumber put the new web app
through its paces

34
00:02:29,780 --> 00:02:35,180
by setting the shouty_test_depth
environment variable to web

35
00:02:35,180 --> 00:02:36,700
when we run Cucumber

36
00:02:37,840 --> 00:02:43,320
This setting causes the scenarios
to be run through the browser via Selenium

37
00:02:43,320 --> 00:02:45,040
and if you watch closely

38
00:02:45,040 --> 00:02:48,440
you can see the message being typed
into the form as it runs

39
00:02:50,000 --> 00:02:53,560
You can see it's way slower
to run the scenarios via browser

40
00:02:54,000 --> 00:02:55,040
Around a minute!

41
00:03:21,180 --> 00:03:25,800
Luckily, we still have our original
much faster version of the acceptance tests

42
00:03:25,800 --> 00:03:27,760
that go directly to the domain model

43
00:03:28,440 --> 00:03:30,420
These run in less than a second

44
00:03:31,200 --> 00:03:35,900
We can run this version by setting
shouty.testDepth to something else

45
00:03:35,900 --> 00:03:37,860
or just leaving it out altogether

46
00:03:39,250 --> 00:03:40,700
Nice!

47
00:03:40,700 --> 00:03:43,488
So we have the best of both worlds it seems

48
00:03:44,300 --> 00:03:48,100
Let's have a look at how this
has been implemented in the features

49
00:03:49,660 --> 00:03:54,620
In this world.rb file here
we now have two separate modules being defined

50
00:03:54,980 --> 00:03:59,440
Our original ShoutyWorld has been
renamed to DomainWorld

51
00:03:59,440 --> 00:04:01,620
and a new WebWorld has been added

52
00:04:02,260 --> 00:04:06,340
WebWorld has exactly the same
methods as the original DomainWorld

53
00:04:06,350 --> 00:04:08,832
but the implementation is quite different

54
00:04:09,856 --> 00:04:11,500
In the sean_shout method

55
00:04:11,500 --> 00:04:16,760
rather than calling the Person domain object
directly to shout the message

56
00:04:16,760 --> 00:04:21,400
the WebWorld calls this visit method
to open the homepage as Sean

57
00:04:21,400 --> 00:04:24,000
then posts the message into
the shout form

58
00:04:25,280 --> 00:04:29,820
Where have these new methods
visit, fill_in, and click_button come from?

59
00:04:30,847 --> 00:04:32,800
They're provided by Capybara

60
00:04:32,800 --> 00:04:36,740
which is a delightful Ruby library
that wraps Selenium WebDriver

61
00:04:36,740 --> 00:04:38,520
in a user-friendly package

62
00:04:39,200 --> 00:04:41,740
I know you're almost drowning
in buzzwords at this point

63
00:04:41,740 --> 00:04:45,360
Don't worry- we'll clear up this in a moment

64
00:04:45,360 --> 00:04:46,800
Let's continue with the tour

65
00:04:48,140 --> 00:04:52,980
Down here, we examine the value of
the shouty_test_depth environment variable

66
00:04:52,980 --> 00:04:54,240
If it's 'web'

67
00:04:54,250 --> 00:04:59,220
we load Capybara, configure it for Selenium
tell it how to boot up our web app

68
00:04:59,220 --> 00:05:04,120
then finally, tell Cucumber to use
the WebWorld in the step definitions

69
00:05:05,160 --> 00:05:09,820
The alternative, of course
is just to use the DomainWorld as normal

70
00:05:09,820 --> 00:05:13,600
Let's walk through what happens
when a scenario runs using the WebWorld

71
00:05:14,420 --> 00:05:18,500
When Cucumber runs the
'Sean shouts, "Free bagels!"' step

72
00:05:18,500 --> 00:05:22,559
it searches for the corresponding
step definition and executes it

73
00:05:23,340 --> 00:05:28,960
Now, the code in that step definition
calls the sean_shout method on the World

74
00:05:28,960 --> 00:05:34,060
which in turn calls the visit method
on Capybara to open the homepage as Sean

75
00:05:34,840 --> 00:05:38,860
Capybara will now tell Selenium WebDriver
to open a browser at that URL

76
00:05:39,540 --> 00:05:43,240
Selenium tells Firefox what it needs to do

77
00:05:43,240 --> 00:05:48,000
and when the browser opens that URL
our website will get a request for the page

78
00:05:48,000 --> 00:05:51,487
we render the page on the server
and the browser displays it

79
00:05:52,240 --> 00:05:58,340
Next, the World asks Capybara to fill out
and submit the shout form

80
00:05:58,340 --> 00:06:03,520
which causes it to give instructions to Selenium
which in turn causes button clicks in the browser

81
00:06:04,287 --> 00:06:05,750
The form is submitted

82
00:06:05,750 --> 00:06:09,663
the server calls the core domain
to broadcast a shout

83
00:06:14,527 --> 00:06:20,159
In contrast the DomainWorld implementation
of sean_shout calls the domain model directly

84
00:06:21,183 --> 00:06:25,535
Notice this is exactly the same code
as the web server uses

85
00:06:27,300 --> 00:06:31,900
Using multiple worlds like this
allows us to choose the strategy

86
00:06:31,900 --> 00:06:33,720
for automating our application

87
00:06:34,495 --> 00:06:37,500
The strategy that talks directly
to the core domain model

88
00:06:37,500 --> 00:06:40,040
gives us fast feedback
and lets us test where the

89
00:06:40,040 --> 00:06:42,940
heart of the application's
behaviour is implemented

90
00:06:43,720 --> 00:06:46,900
We've now added a second strategy
that allows us to prove this behavior

91
00:06:46,900 --> 00:06:49,840
still works when presented via the web UI

92
00:06:51,040 --> 00:06:52,920
You might be wondering why we need both?

93
00:06:53,439 --> 00:06:57,279
Why didn't we just start driving our way in
from the web UI in the beginning?

94
00:06:59,080 --> 00:07:04,960
We've found that focusing on driving out
a domain model from our scenarios first

95
00:07:04,960 --> 00:07:07,320
modelling by example

96
00:07:07,320 --> 00:07:11,620
gives us fast feedback about
our understanding of new problem domains

97
00:07:12,080 --> 00:07:15,100
We don't get distracted by
solution domain complexities like

98
00:07:15,100 --> 00:07:18,300
web servers, HTML, and so on

99
00:07:18,300 --> 00:07:21,860
while we're still just trying to understand
the core of the problem

100
00:07:23,340 --> 00:07:27,360
In the long run, we also find that
staying focused on the core domain

101
00:07:27,360 --> 00:07:30,820
helps us build scenarios that are
more stable over time

102
00:07:31,839 --> 00:07:34,750
User interfaces tend to change
a lot more often

103
00:07:34,750 --> 00:07:37,471
than the core business rules of the domain

104
00:07:39,260 --> 00:07:43,160
Building scenarios that make sense
even without a user interface

105
00:07:43,160 --> 00:07:46,360
also helps us to avoid
our tests from becoming too

106
00:07:46,360 --> 00:07:47,720
Imperative

107
00:07:48,740 --> 00:07:52,280
Most teams who write and run their cukes
against the user interface

108
00:07:52,280 --> 00:07:58,280
end it with a lot of incidental detail
in their scenarios about the UI interaction

109
00:07:58,280 --> 00:07:59,740
Solution domain stuff

110
00:08:00,767 --> 00:08:03,100
These scenarios are poor documentation

111
00:08:03,600 --> 00:08:07,480
They're too busy talking about
how the user performs a task

112
00:08:07,480 --> 00:08:10,360
rather than what the user is trying to achieve

113
00:08:11,380 --> 00:08:15,100
For example we might have written
the scenario like this instead

114
00:08:18,840 --> 00:08:21,760
This scenario doesn't illustrate
the behaviour very well

115
00:08:22,560 --> 00:08:26,000
If you didn't know anything about Shouty
and were trying to understand it

116
00:08:26,000 --> 00:08:29,600
through the examples written like this
you'd have a tough time

117
00:08:30,460 --> 00:08:32,680
It makes for lousy documentation

118
00:08:34,320 --> 00:08:39,840
Notice how the language used in this scenario
the URLs, the CSS selectors

119
00:08:39,840 --> 00:08:43,040
even the filling in fields
and clicking of buttons

120
00:08:43,040 --> 00:08:46,120
is from the solution domain
not the problem domain

121
00:08:47,140 --> 00:08:50,720
It tells you nothing about
your team's ubiquitous language

122
00:08:52,680 --> 00:08:55,020
Finally, this scenario is brittle

123
00:08:55,520 --> 00:08:59,880
If you need to change the details
of the interaction for sending a shout

124
00:08:59,880 --> 00:09:02,060
such as the way you authenticate

125
00:09:02,060 --> 00:09:05,380
you'd need to come back
and change every scenario that involves shouting

126
00:09:06,280 --> 00:09:12,640
By pushing the how down
your scenarios will remain truer for longer

127
00:09:13,520 --> 00:09:16,880
The opposite of the imperative style
where we express the scenarios

128
00:09:16,880 --> 00:09:19,960
using problem domain language is known as a

129
00:09:19,960 --> 00:09:21,360
Declarative Style

130
00:09:22,160 --> 00:09:26,320
In this style, we try to describe
what the user is trying to achieve

131
00:09:26,320 --> 00:09:28,400
rather than how they do it

132
00:09:29,720 --> 00:09:33,360
Thanks to the declarative style
we've been using through the rest of the series

133
00:09:33,360 --> 00:09:36,800
we were able to easily swap in a
different strategy for automating

134
00:09:36,800 --> 00:09:41,040
our application through the web
without changing our specifications

135
00:09:42,040 --> 00:09:47,740
If there are other interfaces to our application
like a rest API or a mobile app

136
00:09:47,740 --> 00:09:51,160
we can continue to use this pattern
adding new strategies

137
00:09:51,160 --> 00:09:54,380
that run our scenarios through
these new layers of the stack

138
00:09:55,860 --> 00:10:02,280
Remember, each of these strategies uses
exactly the same scenarios and step definitions

139
00:10:03,320 --> 00:10:08,900
This means the investment you put into
writing your scenarios pays back over and over

140
00:10:08,900 --> 00:10:11,980
as you reuse them to validate
the behaviour of the application

141
00:10:11,980 --> 00:10:13,600
from these different perspectives

142
00:10:14,780 --> 00:10:18,660
This is a major advantage of having
pushed the details of how Sean shouts

143
00:10:18,660 --> 00:10:20,080
down into a helper method

144
00:10:20,840 --> 00:10:23,600
If this detail was still up
in the step definition

145
00:10:23,600 --> 00:10:28,480
or worse, in the scenario itself
we wouldn't have this flexibility

146
00:10:29,800 --> 00:10:33,480
In general, the structure emerging
in our application and test code

147
00:10:33,480 --> 00:10:36,980
is called a ports and adapters architecture, or

148
00:10:36,980 --> 00:10:38,580
Hexagonal Architecture

149
00:10:39,540 --> 00:10:42,560
You can think of ports and adapters
as a direct analogy

150
00:10:42,560 --> 00:10:45,160
to physical devices with plugs and sockets

151
00:10:45,880 --> 00:10:49,140
For example, the HDMI port on this laptop

152
00:10:49,140 --> 00:10:52,720
lets me plug in any kind of display
that also has a HDMI port

153
00:10:53,680 --> 00:10:58,240
If I need to use a VGA display
I can use an adapter between the two

154
00:10:59,700 --> 00:11:02,000
In a hexagonal architecture

155
00:11:02,000 --> 00:11:05,200
the inner hexagon contains
your core business logic

156
00:11:06,160 --> 00:11:10,200
This is where the if statements that
deliver the most value to your stakeholders

157
00:11:10,200 --> 00:11:11,180
should live

158
00:11:12,320 --> 00:11:14,880
The inner hexagon knows nothing about
the outside world:

159
00:11:14,880 --> 00:11:20,400
your web servers, your databases, your email
sending service, or your enterprise message bus

160
00:11:21,200 --> 00:11:23,440
It's pure business logic

161
00:11:24,400 --> 00:11:28,560
We expose this core behavior via
one or more ports

162
00:11:29,520 --> 00:11:33,600
A port is really just a protocol
an API if you like

163
00:11:34,320 --> 00:11:38,560
Any component who understands that protocol
can then plug in and interact

164
00:11:38,560 --> 00:11:40,400
with the core through the port

165
00:11:41,360 --> 00:11:44,200
We call that component an adapter

166
00:11:44,200 --> 00:11:48,880
It's the adapter's job to expose
the core domain logic to the outside world

167
00:11:50,100 --> 00:11:52,960
In Shouty, there's just one port

168
00:11:52,960 --> 00:11:57,360
the API to our domain model
made up of the Person and Network classes

169
00:11:58,220 --> 00:12:01,520
We've plugged in two different adapters
to this little port:

170
00:12:01,520 --> 00:12:05,200
the WebApp, which exposes
Shouty's core domain over the web

171
00:12:05,200 --> 00:12:08,720
for users (or Selenium WebDriver)
to interact with

172
00:12:09,620 --> 00:12:11,640
And the DomainWorld

173
00:12:11,640 --> 00:12:14,360
which lets Cucumber
drive the application directly

174
00:12:15,480 --> 00:12:18,520
Both are clients of the same API

175
00:12:20,840 --> 00:12:26,100
The hexagonal architecture is a terrific fit
for teams who care about testability

176
00:12:26,100 --> 00:12:29,640
In fact, it was invented precisely
to allow for testability

177
00:12:29,640 --> 00:12:33,680
back in the days when thick client GUIs
were impossible to automate

178
00:12:34,580 --> 00:12:37,700
By separating the core domain logic from the GUI

179
00:12:37,700 --> 00:12:43,100
these TDD pioneers were able to plug
their tests into the same port as the GUI

180
00:12:43,100 --> 00:12:46,080
and still test most of
the application's behaviour

181
00:12:47,520 --> 00:12:50,920
If you have the discipline
to keep your code separated like this

182
00:12:50,920 --> 00:12:52,880
you benefit from being able to
run the tests

183
00:12:52,880 --> 00:12:56,800
against the most business-valuable
lines of code in your codebase

184
00:12:56,800 --> 00:12:58,420
the core domain

185
00:12:58,420 --> 00:13:00,480
in the shortest amount of time

186
00:13:01,760 --> 00:13:05,560
Tests that hit pure business logic
can run lightning fast

187
00:13:05,560 --> 00:13:08,560
meaning it's cheap to get
really thorough feedback

188
00:13:08,560 --> 00:13:11,280
about whether that logic is behaving correctly

189
00:13:12,960 --> 00:13:14,480
Let's get back to the code

190
00:13:15,120 --> 00:13:19,700
To give us a way to test the app manually
the Shouty developers have kindly added this

191
00:13:19,700 --> 00:13:21,920
config.ru file

192
00:13:21,920 --> 00:13:25,640
which starts the web server pre-configured
with some familiar test data

193
00:13:26,600 --> 00:13:28,620
This means we're able to
test the web app

194
00:13:28,620 --> 00:13:32,640
without having to create accounts for people -
a feature we don't have yet!

195
00:13:34,160 --> 00:13:37,740
So we should be able to
open our browser tab as Sean

196
00:13:37,740 --> 00:13:42,260
then another tab as Lucy
send a shout from Sean

197
00:13:42,260 --> 00:13:45,400
refresh Lucy's page and see-

198
00:13:45,400 --> 00:13:48,340
wait a minute! Where's Sean Shout?

199
00:13:49,660 --> 00:13:51,100
This is odd -

200
00:13:51,100 --> 00:13:56,040
The scenario is passing
but there's nothing appearing on Lucy's page

201
00:13:57,140 --> 00:13:58,420
What's going on?

202
00:13:59,500 --> 00:14:03,800
The answer lies in the implementation
of our Then step

203
00:14:05,120 --> 00:14:07,880
Reading it, we can see that
the step definition

204
00:14:07,880 --> 00:14:10,900
is going directly to the domain model
to discover the messages

205
00:14:10,900 --> 00:14:12,460
that Lucy has heard

206
00:14:13,720 --> 00:14:18,120
This shouldn't have been a surprise to us -
it's always been that way -

207
00:14:18,120 --> 00:14:23,620
but since our When step now hits the UI
we would expect this Then step

208
00:14:23,620 --> 00:14:26,000
to also adopt the same strategy

209
00:14:27,480 --> 00:14:31,580
When you start to mix different
depths of testing as we’re doing here

210
00:14:31,580 --> 00:14:37,180
a good rule of thumb is to keep the depth of your
When and Then steps consistent

211
00:14:38,300 --> 00:14:42,580
It’s often advisable to bypass layers
and reach down deeper into the stack

212
00:14:42,580 --> 00:14:45,120
to set up state in the Given steps

213
00:14:46,100 --> 00:14:49,300
But if we carry out an action via the UI

214
00:14:49,300 --> 00:14:53,840
the outcome check in the Then step
should also be done through the UI

215
00:14:56,140 --> 00:15:00,660
Let’s remedy this situation by
pushing the code in this step definition

216
00:15:00,660 --> 00:15:01,980
into a helper method

217
00:15:02,980 --> 00:15:04,720
Then we’ll be able to have
two different strategies

218
00:15:04,720 --> 00:15:07,120
for checking the messages
that a user has heard

219
00:15:08,280 --> 00:15:11,340
Once we have a failing test for
the web strategy

220
00:15:11,340 --> 00:15:15,840
we can drive out the behaviour in the UI
to display the user’s messages

221
00:15:17,020 --> 00:15:19,820
We’ll focus on a single scenario
while we do this work

222
00:15:20,780 --> 00:15:24,140
Once we’ve got that one passing
to our satisfaction

223
00:15:24,140 --> 00:15:27,120
we can apply the same change across
the rest of the scenarios

224
00:15:28,540 --> 00:15:33,660
This very basic scenario, where Lucy hears Sean
is a good place to start

225
00:15:35,380 --> 00:15:38,960
Let's extract a method
from the body of the step definition

226
00:15:38,960 --> 00:15:41,440
and put it in our DomainWorld

227
00:15:49,140 --> 00:15:50,820
That scenario is still passing

228
00:15:51,600 --> 00:15:52,400
Good

229
00:15:53,920 --> 00:15:56,240
Now, when we run it through the web

230
00:15:56,240 --> 00:15:59,040
we’re shown we need to add
that method to the WebWorld

231
00:16:00,800 --> 00:16:02,880
How will we fetch the messages heard?

232
00:16:03,760 --> 00:16:05,500
The first thing we’ll need to do is log in

233
00:16:05,500 --> 00:16:07,780
to make sure we’re reading the messages
for the correct user

234
00:16:08,420 --> 00:16:10,720
So we can re-use this
helper method we’ve already built

235
00:16:11,920 --> 00:16:15,620
Now, we’ll need to
scrape the messages off the HTML page

236
00:16:16,600 --> 00:16:20,020
Remember we’re going test-first here
so we don’t have this markup yet

237
00:16:20,840 --> 00:16:22,280
That's not a problem

238
00:16:22,280 --> 00:16:25,600
We can use the test to help us design
what the markup should look like

239
00:16:26,940 --> 00:16:31,660
Let’s assume that each message will be
an element with a message class on it

240
00:16:32,480 --> 00:16:35,840
We can ask Capybara to give us all
the elements with that class

241
00:16:36,820 --> 00:16:40,060
That gives us a list of
Capybara HTML Elements

242
00:16:40,060 --> 00:16:43,520
which we can then transform into
a list of their text content

243
00:16:44,640 --> 00:16:46,240
Let's watch this test fail

244
00:16:50,200 --> 00:16:51,420
That looks OK.

245
00:16:52,260 --> 00:16:54,760
Let's play fake it till you make it

246
00:16:54,760 --> 00:16:57,540
just to check this assertion
is doing the right thing

247
00:16:58,220 --> 00:17:01,920
We’ll hard-code the HTML we want
into the template, here

248
00:17:04,500 --> 00:17:08,100
This gives us a chance to
talk with our designer about the markup

249
00:17:08,100 --> 00:17:13,180
We go over for a chat and he loves it
so we can press on!

250
00:17:15,020 --> 00:17:18,900
The next step is to
make the HTML template dynamic

251
00:17:18,900 --> 00:17:22,600
and have it display the actual list of
messages heard by the user

252
00:17:23,480 --> 00:17:27,220
We could continue using the
Cucumber scenario to drive this out

253
00:17:27,220 --> 00:17:31,840
but it would be better to zoom in and focus
on some unit tests for the web app now

254
00:17:32,920 --> 00:17:36,440
That way, if this behaviour ever
slips loose in the future

255
00:17:36,440 --> 00:17:40,160
there will be a unit test pointing us
to exactly where we need to go to fix it

256
00:17:41,600 --> 00:17:45,400
Luckily, the web app has already been built
with some unit tests around it

257
00:17:47,420 --> 00:17:51,920
These tests load the
Sinatra web app in isolation

258
00:17:51,920 --> 00:17:55,460
passing it a hash of people that
just contains test doubles

259
00:17:56,240 --> 00:17:59,020
We could have used real instances
from our domain model

260
00:17:59,020 --> 00:18:01,120
but as we explained in the last episode

261
00:18:01,120 --> 00:18:04,500
using test doubles helps us
to see the protocol on the port

262
00:18:04,500 --> 00:18:07,240
between the web app adapter
and our core domain

263
00:18:09,240 --> 00:18:13,240
We use a library called rack/test
to make requests to the web app

264
00:18:13,240 --> 00:18:17,040
and load the response into
a Capybara HTML document

265
00:18:17,040 --> 00:18:19,500
so we can make queries
and assertions about the HTML

266
00:18:19,500 --> 00:18:21,060
in the response if we want to

267
00:18:22,800 --> 00:18:25,200
The tests are organized by request

268
00:18:25,200 --> 00:18:29,500
so that when we run them, we get some
nice documentation about how the app behaves

269
00:18:30,780 --> 00:18:33,180
We need a new test for the GET request

270
00:18:33,180 --> 00:18:37,000
which simulates the situation where
Lucy has heard a couple of messages...

271
00:18:41,900 --> 00:18:43,520
and views her homepage

272
00:18:44,800 --> 00:18:48,960
We’d expect to be able to find the message text
in each of the message elements

273
00:18:51,780 --> 00:18:56,900
When we run this, it fails because
we’re just hard-coding the message at the moment

274
00:18:57,300 --> 00:18:59,200
Let's TDD our solution

275
00:19:01,500 --> 00:19:04,560
If you'd like to try this yourself
just pause the video here

276
00:19:04,560 --> 00:19:07,920
and see if you can figure out what to do next
before we show you

277
00:19:10,460 --> 00:19:14,000
Starting in the template, we can look
for a local variable

278
00:19:14,000 --> 00:19:17,887
let’s call it messages_heard
and iterate over it

279
00:19:18,240 --> 00:19:20,940
For each message, we’ll write a message element

280
00:19:25,880 --> 00:19:26,740
There

281
00:19:28,060 --> 00:19:31,440
Now we need to set that
messages_heard variable for the template

282
00:19:32,150 --> 00:19:35,039
We do that from within the
GET request handler in the web app

283
00:19:36,250 --> 00:19:38,500
We need to get the messages_heard for the user

284
00:19:38,500 --> 00:19:44,255
which we can fetch from the @people hash
using the name param as the key to find them

285
00:19:45,279 --> 00:19:51,167
Now we pass the messages_heard through
to the view template in this locals hash

286
00:19:52,740 --> 00:19:54,020
Let's give that a try

287
00:20:13,860 --> 00:20:17,800
Great! Suddenly, everything is green!

288
00:20:19,240 --> 00:20:24,420
Try a quick manual test for yourself
creating a couple of tabs as Sean and Lucy

289
00:20:24,420 --> 00:20:27,060
and satisfy yourself that it’s working now

290
00:20:28,080 --> 00:20:30,440
Now that we’ve proved our
messages_heard_by method

291
00:20:30,440 --> 00:20:33,400
works for both domain and web strategies

292
00:20:33,400 --> 00:20:36,500
let’s use that method in
all the step definitions

293
00:20:36,500 --> 00:20:39,580
so that every scenario
that checks for messages_heard

294
00:20:39,580 --> 00:20:42,120
will do that check in a consistent way

295
00:20:43,140 --> 00:20:48,300
This is just a matter of finding each call
to ask a Person domain object for messages_heard

296
00:20:48,300 --> 00:20:51,080
and converting it to use
our new helper method instead

297
00:20:54,399 --> 00:20:56,959
Let's run all the scenarios in the shout feature

298
00:21:01,100 --> 00:21:03,880
Great. It looks like we're done

299
00:21:05,180 --> 00:21:08,660
If we look at the other feature
Premium accounts

300
00:21:08,660 --> 00:21:12,300
we can see that there’s
a similar problem to the one we’ve just resolved

301
00:21:12,900 --> 00:21:18,020
This last step
'Then Sean should have n credits'

302
00:21:18,020 --> 00:21:21,140
goes direct to the domain model
to check Sean’s credits

303
00:21:21,140 --> 00:21:23,880
rather than having that
extra layer of indirection

304
00:21:23,880 --> 00:21:27,420
that would allow us to use a domain
or a web strategy for the check

305
00:21:28,860 --> 00:21:31,700
It will be useful practice for you
to go through and apply

306
00:21:31,700 --> 00:21:34,860
exactly what we just did to this step definition

307
00:21:35,660 --> 00:21:38,080
We'll leave that as an exercise for you

308
00:21:40,000 --> 00:21:42,280
Let's fast-forward to the point
where this is done

309
00:21:43,800 --> 00:21:47,640
Now, we can run all of our scenarios
at both levels

310
00:21:47,640 --> 00:21:50,980
against the domain, and against the web UI

311
00:21:52,360 --> 00:21:53,800
This is awesome!

312
00:21:55,240 --> 00:21:56,240
Isn't it?

313
00:21:56,920 --> 00:22:01,040
We've talked a lot about the benefits of
automated tests in this series

314
00:22:01,040 --> 00:22:05,060
but let’s consider the flip side for a moment
and look at the costs

315
00:22:06,600 --> 00:22:10,260
Every automated test in your system
comes at a cost

316
00:22:11,080 --> 00:22:14,000
You have the cost of 
writing it in the first place

317
00:22:14,000 --> 00:22:17,440
the cost of waiting for it to run each time

318
00:22:17,440 --> 00:22:22,140
the cost of changing it when the
desired behaviour of the application changes

319
00:22:22,140 --> 00:22:26,300
and the cost of debugging it
when it fails for no good reason

320
00:22:28,120 --> 00:22:31,720
When the majority of your tests hit
the application through the user interface

321
00:22:31,720 --> 00:22:33,760
you get a great benefit

322
00:22:33,760 --> 00:22:37,920
from knowing that each scenario
is using the system exactly as a user would

323
00:22:38,940 --> 00:22:42,920
Yet the downside is that
these tests are much slower to run

324
00:22:42,920 --> 00:22:44,740
and are often also much less reliable

325
00:22:46,560 --> 00:22:50,000
A well-known metaphor to help you
think about this problem is the

326
00:22:50,000 --> 00:22:52,000
Agile Testing Pyramid

327
00:22:52,800 --> 00:22:56,960
At the base of the pyramid
you have a large number of unit tests -

328
00:22:57,840 --> 00:23:04,200
shallow tests that directly hit isolated
individual classes and modules in your solution

329
00:23:05,720 --> 00:23:12,240
The pyramid gets narrower as you go up
indicating that as the depth of tests increases

330
00:23:12,240 --> 00:23:14,160
the less of them you should have

331
00:23:14,760 --> 00:23:18,080
At the very top of the pyramid
where the tests go right through

332
00:23:18,080 --> 00:23:20,760
the whole application stack

333
00:23:20,760 --> 00:23:22,460
you want as few as possible

334
00:23:23,500 --> 00:23:26,980
Just enough to give you confidence
the thing is working

335
00:23:28,720 --> 00:23:31,740
When you drive most of
your behaviour through the GUI

336
00:23:31,740 --> 00:23:36,260
you end up with the opposite -
more of a testing ice cream cone

337
00:23:37,140 --> 00:23:42,660
Now I love an ice cream on a hot summer’s day
but when your test suite looks like this

338
00:23:42,660 --> 00:23:46,660
you’re waiting hours for test results
and there are generally at least

339
00:23:46,660 --> 00:23:50,280
one or two random failures in every build

340
00:23:52,440 --> 00:23:56,280
Although we have the choice to
run every Shouty scenario through the GUI

341
00:23:56,280 --> 00:24:00,300
the Agile Testing Pyramid tells us
that would be a bad idea

342
00:24:01,500 --> 00:24:07,780
We need to select a few representative or
key examples to run through the web UI

343
00:24:07,780 --> 00:24:09,720
and run the rest through the domain

344
00:24:11,000 --> 00:24:13,020
How do we choose those key examples?

345
00:24:14,800 --> 00:24:17,420
Let’s try and think about
what could possibly go wrong

346
00:24:18,176 --> 00:24:21,500
We want to identify the minimum number of
scenarios that would give us confidence

347
00:24:21,500 --> 00:24:22,784
the system is working

348
00:24:23,560 --> 00:24:26,900
Remember: both our core domain
and our web server

349
00:24:26,900 --> 00:24:29,260
are protected by their own unit tests

350
00:24:29,260 --> 00:24:32,000
so we just need a few checks
for basic correctness

351
00:24:32,720 --> 00:24:37,740
Would it be enough to just test this scenario
the one where the listener is within range?

352
00:24:39,060 --> 00:24:41,600
If we did that, what could possibly go wrong?

353
00:24:43,260 --> 00:24:46,000
With our tester’s hat on
we can imagine a bug

354
00:24:46,000 --> 00:24:49,400
where the web server’s template
didn’t render multiple messages

355
00:24:50,240 --> 00:24:52,220
This scenario only works for one

356
00:24:53,340 --> 00:24:57,080
So we could add this scenario
the one where there are two shouts

357
00:24:57,920 --> 00:25:00,920
Yet we’d easily catch that bug in manual testing

358
00:25:00,920 --> 00:25:03,740
and could then pin it down with
a unit test on the web server

359
00:25:05,020 --> 00:25:08,340
So we don’t need to run this as a
full-stack test every time

360
00:25:09,260 --> 00:25:10,400
In fact

361
00:25:10,400 --> 00:25:12,960
to do so would be wasteful

362
00:25:14,752 --> 00:25:18,336
How about the scenario about
the listener being out of range?

363
00:25:19,000 --> 00:25:22,460
If we skip that in our web-depth Cucumber run

364
00:25:22,460 --> 00:25:25,500
would we leave ourselves vulnerable
to a dangerous bug?

365
00:25:27,040 --> 00:25:30,860
Well, it’s true that if people heard messages
that were not meant for them

366
00:25:30,860 --> 00:25:33,180
it could make us look pretty bad

367
00:25:34,208 --> 00:25:36,256
But how likely is this to happen?

368
00:25:37,020 --> 00:25:39,700
That logic is all in the core domain

369
00:25:39,700 --> 00:25:43,160
the web server just renders
the messages returned by the core

370
00:25:43,750 --> 00:25:47,520
So there’s almost a zero risk of
this bug ever leaking out

371
00:25:48,280 --> 00:25:51,860
Again, a full-stack test for this
behaviour would be wasteful

372
00:25:54,460 --> 00:25:57,340
Although the same goes for
the logic about a long message

373
00:25:57,340 --> 00:26:00,650
we know that there’s potential for
there to be bugs in the interaction

374
00:26:00,650 --> 00:26:03,480
of the UI for longer messages

375
00:26:03,480 --> 00:26:05,440
so it makes sense for us to run this one

376
00:26:06,300 --> 00:26:09,140
Let’s mark it up as @high-risk

377
00:26:09,140 --> 00:26:13,120
and mark the one where the listener is
within range as @high-impact

378
00:26:13,920 --> 00:26:15,600
We’ll explain those terms in a moment

379
00:26:17,020 --> 00:26:23,880
Now, we can run the tests at the top of our pyramid
using those tags and the web_test_depth setting

380
00:26:24,640 --> 00:26:29,840
Now we have three different levels of tests in
our pyramid that we want to run to check our code

381
00:26:29,840 --> 00:26:31,260
The unit tests

382
00:26:31,260 --> 00:26:36,660
the core domain acceptance tests
and the key examples running as full-stack tests

383
00:26:37,696 --> 00:26:43,072
Let's set up a rake task to run all
of these tests for us with a single command

384
00:26:44,600 --> 00:26:47,160
First we’ll create a new Rakefile

385
00:26:48,120 --> 00:26:51,960
We’ll add a default task that
depends on three tasks

386
00:26:51,960 --> 00:26:57,260
unit test, core acceptance tests
and web acceptance tests

387
00:26:58,940 --> 00:27:01,000
Unit tests is easy to implement

388
00:27:01,000 --> 00:27:02,780
We just shell out to RSpec

389
00:27:04,320 --> 00:27:06,700
Core acceptance tests is very similar

390
00:27:06,700 --> 00:27:08,672
but we shell out to Cucumber instead

391
00:27:09,960 --> 00:27:13,860
Now for the web acceptance tests
we just need to shell out to Cucumber

392
00:27:13,860 --> 00:27:17,820
but this time set the shouty_test_depth
environment variable

393
00:27:17,820 --> 00:27:20,180
and pass the tags configuration switch

394
00:27:20,840 --> 00:27:23,520
Now when we run `rake`
from the command-line

395
00:27:23,520 --> 00:27:27,860
it runs all three layers of our testing pyramid
starting from the bottom up

396
00:27:33,540 --> 00:27:34,620
One last thing:

397
00:27:35,300 --> 00:27:40,050
When we automate web pages, we need to
refer to user interface elements and actions

398
00:27:40,050 --> 00:27:42,720
buttons, links, text, clicks, etc

399
00:27:43,480 --> 00:27:48,040
This is solution domain jargon
we’ve managed to keep out of our scenarios

400
00:27:48,040 --> 00:27:48,860
and that’s good!

401
00:27:49,740 --> 00:27:51,280
But it has to go somewhere

402
00:27:52,880 --> 00:27:55,880
On larger projects, it becomes useful
to create abstractions called

403
00:27:55,880 --> 00:27:58,850
page objects to represent
the things being filled in

404
00:27:58,850 --> 00:28:00,700
clicked, and examined for content

405
00:28:01,160 --> 00:28:06,020
For example, we might have a homepage object
with a method called shout

406
00:28:06,020 --> 00:28:09,860
that encapsulated the calls to interact
with the elements on the web page

407
00:28:10,520 --> 00:28:14,800
This allows you to easily reuse code
and keep it easy to read

408
00:28:16,000 --> 00:28:18,560
You can easily build page objects on your own

409
00:28:18,560 --> 00:28:20,600
but if you’re feeling lazy
there are a few libraries that

410
00:28:20,600 --> 00:28:23,420
reduce the amount of boilerplate code
you need to write

411
00:28:23,420 --> 00:28:28,040
Jeff “Cheezy” Morgan’s 'page-objects' gem
is a popular choice

412
00:28:29,660 --> 00:28:35,380
The page objects pattern is a great fit
for keeping your web automation code tidy

413
00:28:35,380 --> 00:28:38,600
but we strongly recommend that you try to

414
00:28:38,600 --> 00:28:42,520
push as many of your tests
down the pyramid first

415
00:28:43,580 --> 00:28:47,000
You can use page objects together with
the hexagonal architecture pattern

416
00:28:47,000 --> 00:28:49,000
we’ve shown you in this episode

417
00:28:49,000 --> 00:28:51,680
so that when you do need to hit the web UI

418
00:28:51,680 --> 00:28:54,180
you can do that through neat and tidy code

419
00:28:54,980 --> 00:28:58,060
That's it kids, school's out!

420
00:28:58,060 --> 00:29:00,800
Time to step out into the real world

421
00:29:02,100 --> 00:29:07,660
This has been an intense episode
and we’ve thrown a lot of new concepts at you -

422
00:29:07,660 --> 00:29:12,980
the hexagonal architecture, the strategy
pattern and the agile testing pyramid

423
00:29:14,320 --> 00:29:20,140
Please take time to watch this video over
a few times until you understand these concepts

424
00:29:20,140 --> 00:29:23,080
and study the exercises and reflection questions

425
00:29:24,060 --> 00:29:29,980
We want you to remember that acceptance tests
don’t have to be full-stack tests

426
00:29:30,600 --> 00:29:33,500
In fact, it’s often a mistake if they are

427
00:29:34,840 --> 00:29:40,220
Don’t fall into the trap of building yet another
testing ice cream cone for your project

428
00:29:41,000 --> 00:29:44,000
Have developers and testers work side-by-side

429
00:29:44,000 --> 00:29:48,200
to maximize the value you get
from your testing investment

430
00:29:48,200 --> 00:29:52,440
by pushing as many tests
as you can down to the lowest level

431
00:29:53,380 --> 00:29:59,560
The responsibility for the health and wellbeing
of the world’s Cucumber suites rests with you now

432
00:30:00,580 --> 00:30:03,200
Use your knowledge wisely!

433
00:30:05,760 --> 00:30:10,440
If you remember one thing from
the video series, remember this:

434
00:30:11,360 --> 00:30:14,520
The software you write is just a model -

435
00:30:15,540 --> 00:30:19,440
a model of your team's understanding
of the problem domain

436
00:30:20,680 --> 00:30:25,280
The better that understanding is
the better the software will be

437
00:30:26,580 --> 00:30:31,060
Put your effort into understanding
the problem together

438
00:30:31,060 --> 00:30:34,320
and the software will take care of itself

439
00:30:36,600 --> 00:30:39,400
Goodbye from all of us on Cucumber School

440
00:30:39,400 --> 00:30:40,960
and have fun out there!

441
00:30:42,220 --> 00:30:44,200
Captions created by Jayson Smith for Cucumber Ltd.
